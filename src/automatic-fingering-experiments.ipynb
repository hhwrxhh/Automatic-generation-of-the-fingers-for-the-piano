{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.734331Z",
     "iopub.status.busy": "2025-06-15T17:39:42.733995Z",
     "iopub.status.idle": "2025-06-15T17:39:42.740392Z",
     "shell.execute_reply": "2025-06-15T17:39:42.739414Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.734307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from music21 import pitch\n",
    "from pprint import pprint, pformat\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.761674Z",
     "iopub.status.busy": "2025-06-15T17:39:42.761340Z",
     "iopub.status.idle": "2025-06-15T17:39:42.766438Z",
     "shell.execute_reply": "2025-06-15T17:39:42.765409Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.761649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BLOCK_LENGTH = 11\n",
    "FUTURE_LENGTH = 5\n",
    "FINGER_SIZE = 5\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "DATA_DIR = \"/kaggle/input/pig-new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.768309Z",
     "iopub.status.busy": "2025-06-15T17:39:42.767964Z",
     "iopub.status.idle": "2025-06-15T17:39:42.772689Z",
     "shell.execute_reply": "2025-06-15T17:39:42.771713Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.768279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "block_future = [(11, 5)]\n",
    "hands = [\"right\", \"left\"]\n",
    "interval_to_midi = {\n",
    "    # \"Unison\": 0,\n",
    "    # \"Minor Second\": 1,\n",
    "    # \"Major Second\": 2,\n",
    "    # \"Minor Third\": 3,\n",
    "    \"Major Third\": 4,\n",
    "    # \"Perfect Fourth\": 5,\n",
    "    # \"Tritone\": 6,\n",
    "    # \"Perfect Fifth\": 7,\n",
    "    # \"Minor Sixth\": 8,\n",
    "    # \"Major Sixth\": 9,\n",
    "    # \"Minor Seventh\": 10,\n",
    "    # \"Major Seventh\": 11,\n",
    "    # \"Octave\": 12\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.794484Z",
     "iopub.status.busy": "2025-06-15T17:39:42.793788Z",
     "iopub.status.idle": "2025-06-15T17:39:42.800734Z",
     "shell.execute_reply": "2025-06-15T17:39:42.799600Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.794448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_pitch_info(pitch):\n",
    "    \"\"\"\n",
    "    Returns white key index and black key flag from pitch string.\n",
    "\n",
    "    The white key index is centered around C4 (i.e., C4 → 0, C5 → 7, C3 → -7).\n",
    "\n",
    "    Args:\n",
    "        pitch (str): Note like \"C4\", \"D#5\", \"Bb3\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: (white_key_val, black_key), where black_key is 1 for sharp/flat, 0 otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Extract the base note and octave\n",
    "    base_note = pitch[0]  # First character (e.g., \"C\", \"D\")\n",
    "    octave = 4  # Default octave is 4 (octave start from middle C)\n",
    "    \n",
    "    note_val = {\"C\": 0, \"D\": 1, \"E\": 2, \"F\": 3, \"G\": 4, \"A\": 5, \"B\": 6}\n",
    "    \n",
    "    # Is the key a black key right next to the base note? (e.g., C#4, D#4)\n",
    "    black_key = 0 # Default is white key\n",
    "\n",
    "    # To tuple that split white/black keys, for allowing the black_key to reduce the span needed \n",
    "    # Note: Minus 4 to center around C4 (Middle c); Times 7 to span octaves (7 semitones)\n",
    "    if pitch[1].isdigit(): # No sharp/flat like \"C4\"\n",
    "        note_val[base_note] += (int(pitch[1]) - 4) * 7\n",
    "    elif pitch[1] == \"#\": # Sharp(1 semitone up) like \"C#4\n",
    "        black_key = 1\n",
    "        note_val[base_note] += (int(pitch[2]) - 4) * 7\n",
    "    elif pitch[1] in [\"b\", \"-\"]: # Flat(1 semitone down) like \"Cb4\"\n",
    "        black_key = 1\n",
    "\n",
    "    return (note_val[base_note], black_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.802299Z",
     "iopub.status.busy": "2025-06-15T17:39:42.802028Z",
     "iopub.status.idle": "2025-06-15T17:39:42.807367Z",
     "shell.execute_reply": "2025-06-15T17:39:42.806434Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.802278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_white_black_diff(pitch1, pitch2):\n",
    "    \"\"\"\n",
    "    Calculate the white-key distance between two pitches.\n",
    "    \n",
    "    Args:\n",
    "        pitch1, pitch2: Note pitch in the format of \"C4\", \"D#5\", etc.\n",
    "\n",
    "    Returns:\n",
    "        int: Semitone distance between two pitches\n",
    "    \"\"\"\n",
    "    \n",
    "    a = extract_pitch_info(pitch1) \n",
    "    b =  extract_pitch_info(pitch2)\n",
    "    return abs(a[0] - b[0]), a[1] + b[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.808745Z",
     "iopub.status.busy": "2025-06-15T17:39:42.808370Z",
     "iopub.status.idle": "2025-06-15T17:39:42.817224Z",
     "shell.execute_reply": "2025-06-15T17:39:42.816084Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.808717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pass_bounds(notes):\n",
    "    \"\"\"\n",
    "    Checks if any note in the list is out of the allowed MIDI range.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass_range = False\n",
    "    for n in notes:\n",
    "        if not (n == 0 or (21 <= n < 108)):\n",
    "            pass_range = True\n",
    "    return pass_range\n",
    "\n",
    "\n",
    "def interval_symmetry(piece, interval):\n",
    "    \"\"\"\n",
    "    Generates symmetrical piece by applying interval shifts across multiple octaves.\n",
    "    \n",
    "    Args:\n",
    "        piece (PianoPiece): The original piano piece object.\n",
    "        interval (int): The interval (in semitones) to use for symmetry transposition.\n",
    "\n",
    "    Returns:\n",
    "        list of PianoPiece: List of transposed, symmetrical versions of the input piece.\n",
    "    \"\"\"\n",
    "    \n",
    "    pieces = []\n",
    "    octaves = [-9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    for octave in octaves:\n",
    "        new_notes = [(n + (octave * interval)) if n != 0 else 0 for n in piece.notes]\n",
    "        if not pass_bounds(new_notes):\n",
    "            pieces.append(PianoPiece(new_notes, \n",
    "                                     piece.fingers, \n",
    "                                     piece.intervals, \n",
    "                                     piece.accidentals, \n",
    "                                     piece.ids, \n",
    "                                     \n",
    "                                     piece.durations,\n",
    "                                     piece.onset,\n",
    "                                     piece.offset,\n",
    "\n",
    "                                     piece.is_3_chord,\n",
    "                                     piece.is_4_chord,\n",
    "                                     piece.is_5_chord,\n",
    "                                     piece.chord_tonic,\n",
    "                                     piece.chord_sixth,\n",
    "                                     piece.chord_second_inversion,\n",
    "                                     \n",
    "                                     piece.white_diff,\n",
    "                                     piece.black_diff,\n",
    "                                     piece.file_name))\n",
    "\n",
    "    return pieces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chord Detection and Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.829947Z",
     "iopub.status.busy": "2025-06-15T17:39:42.829631Z",
     "iopub.status.idle": "2025-06-15T17:39:42.838263Z",
     "shell.execute_reply": "2025-06-15T17:39:42.837086Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.829924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def detect_triad_type(notes):\n",
    "    \"\"\"\n",
    "    Determines the type of chord based on a list of three note names.\n",
    "\n",
    "    Args:\n",
    "        notes (list of int): List of midi values.\n",
    "\n",
    "    Returns:\n",
    "        str: One of \"tonic\", \"sixth\", \"second_inversion\", or \"unknown\".\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        midi_notes = sorted([pitch.Pitch(n).midi for n in notes])\n",
    "        intervals = [midi_notes[i] - midi_notes[0] for i in range(1, 3)]\n",
    "        structure = (0, *intervals)\n",
    "\n",
    "        if structure in [(0, 4, 7), (0, 3, 7)]:\n",
    "            return \"chord_tonic\"\n",
    "        elif structure in [(0, 3, 8), (0, 4, 9)]:\n",
    "            return \"chord_sixth\"\n",
    "        elif structure in [(0, 5, 9), (0, 5, 8)]:\n",
    "            return \"chord_second_inversion\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "    except:\n",
    "        return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.840424Z",
     "iopub.status.busy": "2025-06-15T17:39:42.840058Z",
     "iopub.status.idle": "2025-06-15T17:39:42.849656Z",
     "shell.execute_reply": "2025-06-15T17:39:42.848567Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.840398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mark_chords_with_type(df):\n",
    "    \"\"\"\n",
    "    Adds one-hot encoded columns indicating chord type for triads.\n",
    "    Also adds binary flags: is_3_chord, is_4_chord, is_5_chord.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with a piano piece.\n",
    "\n",
    "    Returns:\n",
    "        Updated DataFrame with new one-hot encoded columns and chord size flags.\n",
    "    \"\"\"\n",
    "    \n",
    "    group_counts = df.groupby([\"Onset\", \"Offset\"]).size().reset_index(name=\"count\")\n",
    "    chord_groups = group_counts[group_counts[\"count\"] >= 3][[\"Onset\", \"Offset\", \"count\"]]\n",
    "\n",
    "    df = df.merge(chord_groups.assign(is_chord=1), on=[\"Onset\", \"Offset\"], how=\"left\")\n",
    "    df[\"is_chord\"] = df[\"is_chord\"].fillna(0).astype(int)\n",
    "    df[\"count\"] = df[\"count\"].fillna(0).astype(int)\n",
    "\n",
    "    df[\"chord_type\"] = \"none\"\n",
    "\n",
    "    for (onset, offset), group_df in df.groupby([\"Onset\", \"Offset\"]):\n",
    "        if len(group_df) == 3:\n",
    "            pitches = group_df[\"PitchName\"].tolist()  \n",
    "            chord_type = detect_triad_type(pitches)\n",
    "            df.loc[(df[\"Onset\"] == onset) & (df[\"Offset\"] == offset), \"chord_type\"] = chord_type\n",
    "\n",
    "    df[\"chord_type\"] = df[\"chord_type\"].replace(\"none\", \"unknown\")\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"chord_type\"], dtype='int')\n",
    "    for i in dummies.columns:\n",
    "        df[i] = dummies[i]\n",
    "\n",
    "    df[\"is_3_chord\"] = (df[\"count\"] == 3).astype(int)\n",
    "    df[\"is_4_chord\"] = (df[\"count\"] == 4).astype(int)\n",
    "    df[\"is_5_chord\"] = (df[\"count\"] == 5).astype(int)\n",
    "    \n",
    "    # dropping unnecessary columns\n",
    "    for i in [\"count\", \"chord_type\", \"unknown\", \"is_chord\"]:\n",
    "        if i in df.columns:\n",
    "            df = df.drop(i, axis=1)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.850886Z",
     "iopub.status.busy": "2025-06-15T17:39:42.850643Z",
     "iopub.status.idle": "2025-06-15T17:39:42.857024Z",
     "shell.execute_reply": "2025-06-15T17:39:42.855924Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.850869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reorganize_fingers(df, hand=\"right\"):\n",
    "    \"\"\"\n",
    "    Reorganizes pitch data for chords or intervals.\n",
    "\n",
    "    For each chord, the notes (and its rows) are sorted in ascending order.\n",
    "    Example: Given a chord G4, E4, and C4 is reordered as C4, E4, G4.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"PitchPs\"] = [pitch.Pitch(p).ps for p in df[\"PitchName\"]]\n",
    "\n",
    "    sorted_df = df.sort_values(by=[\"Onset\", \"PitchPs\"])\n",
    "    sorted_df[\"ID\"] = range(len(sorted_df))\n",
    "    sorted_df = sorted_df.drop(columns=[\"PitchPs\"])\n",
    "    \n",
    "    return sorted_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.858605Z",
     "iopub.status.busy": "2025-06-15T17:39:42.858229Z",
     "iopub.status.idle": "2025-06-15T17:39:42.869956Z",
     "shell.execute_reply": "2025-06-15T17:39:42.869066Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.858572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PianoPiece:\n",
    "    \"\"\"\n",
    "    A data structure representing a piano piece with associated musical and fingering information.\n",
    "\n",
    "    Attributes:\n",
    "        notes : MIDI values representing the notes in the piece.\n",
    "        fingers : Finger numbers corresponding to each note.\n",
    "        intervals : Interval distances between consecutive notes.\n",
    "        accidentals : Accidentals (sharps, flats, naturals) for each note.\n",
    "        ids : Unique identifiers for each note or event.\n",
    "        durations : Durations for each note in seconds.\n",
    "        onset : Onset times (in seconds) for each note.\n",
    "        offset : Offset times (in seconds) for each note.\n",
    "\n",
    "        white_diff : Movement in terms of white keys between notes.\n",
    "        black_diff : Movement in terms of black keys between notes.\n",
    "\n",
    "        chords : Whether the note belongs to a chord.\n",
    "        chord_tonic : Whether the note is in the root (tonic) chord.\n",
    "        chord_sixth : Whether the note is in a sixth chord.\n",
    "        chord_second_inversion : Whether the note is in a second inversion chord.\n",
    "\n",
    "        file_name : Name of the file from which the data was derived.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        notes = None, fingers = None, intervals = None,\n",
    "        accidentals = None, ids = None,\n",
    "        durations = None, onset = None, offset = None,\n",
    "        is_3_chord = None, is_4_chord = None, is_5_chord = None,\n",
    "        chord_tonic = None, chord_sixth = None, chord_second_inversion = None,\n",
    "        white_diff = None, black_diff = None,\n",
    "        file_name: str = \"\"\n",
    "    ):\n",
    "        self.notes = notes\n",
    "        self.fingers = fingers\n",
    "        self.intervals = intervals\n",
    "        self.accidentals = accidentals\n",
    "        self.ids = ids\n",
    "        self.durations = durations\n",
    "        self.onset = onset\n",
    "        self.offset = offset\n",
    "\n",
    "        self.white_diff = white_diff\n",
    "        self.black_diff = black_diff\n",
    "\n",
    "        self.is_3_chord = is_3_chord\n",
    "        self.is_4_chord = is_4_chord\n",
    "        self.is_5_chord = is_5_chord\n",
    "        self.chord_tonic = chord_tonic\n",
    "        self.chord_sixth = chord_sixth\n",
    "        self.chord_second_inversion = chord_second_inversion\n",
    "\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def get_features(self, input_features):\n",
    "        \"\"\"Returns selected features in aligned format for model input.\"\"\"\n",
    "    \n",
    "        feature_map = {\n",
    "            \"fingers\": self.fingers[:-1],\n",
    "            \"notes\": self.notes[:-1],\n",
    "            \"intervals\": self.intervals,\n",
    "            \n",
    "            \"accidentals_current\": self.accidentals[:-1],\n",
    "            \"accidentals_next\": self.accidentals[1:],\n",
    "            \"white_diff\": self.white_diff[:-1],\n",
    "            \"black_diff\": self.black_diff[:-1],\n",
    "            # \"chords\": self.chords[:-1],\n",
    "            \n",
    "            \"is_3_chord\": self.is_3_chord[:-1],\n",
    "            \"is_4_chord\": self.is_4_chord[:-1],\n",
    "            \"is_5_chord\": self.is_5_chord[:-1],\n",
    "            \"chord_tonic\": self.chord_tonic[:-1],\n",
    "            \"chord_sixth\": self.chord_sixth[:-1],\n",
    "            \"chord_second_inversion\": self.chord_second_inversion[:-1],\n",
    "        }\n",
    "        \n",
    "        # Detect invalid features\n",
    "        invalid_features = [name for name in input_features if name not in feature_map]\n",
    "        if invalid_features:\n",
    "            raise ValueError(f\"The following input features are invalid: {invalid_features}\")\n",
    "    \n",
    "        selected = [feature_map[name] for name in input_features]\n",
    "    \n",
    "        if not selected:\n",
    "            raise ValueError(\"No valid features provided for model input.\")\n",
    "    \n",
    "        return [list(x) for x in zip(*selected)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.872676Z",
     "iopub.status.busy": "2025-06-15T17:39:42.872369Z",
     "iopub.status.idle": "2025-06-15T17:39:42.878839Z",
     "shell.execute_reply": "2025-06-15T17:39:42.877728Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.872655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_finger_ranges(df, hand, file_path):\n",
    "    \"\"\"\n",
    "    Validates that finger values in the DataFrame fall within the correct range \n",
    "    for the specified hand. \n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with a piano piece\n",
    "        hand (str): Either 'right' or 'left', indicating the hand being checked.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"Finger\"] = df[\"Finger\"].astype(str).str.split('_').str[0].astype(int)\n",
    "\n",
    "    if hand == \"right\":\n",
    "        invalid_rows = df[(df[\"Finger\"] < 1) | (df[\"Finger\"] > 5)]\n",
    "        if not invalid_rows.empty:\n",
    "            raise ValueError(f\"Invalid right-hand finger values found in {file_path}:\\n{invalid_rows}\")\n",
    "\n",
    "    elif hand == \"left\":\n",
    "        invalid_rows = df[(df[\"Finger\"] < -5) | (df[\"Finger\"] > -1)]\n",
    "        if not invalid_rows.empty:\n",
    "            raise ValueError(f\"Invalid left-hand finger values found in {file_path}:\\n{invalid_rows}\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid hand type: {hand}. Expected 'right' or 'left'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.880226Z",
     "iopub.status.busy": "2025-06-15T17:39:42.879849Z",
     "iopub.status.idle": "2025-06-15T17:39:42.898975Z",
     "shell.execute_reply": "2025-06-15T17:39:42.898071Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.880201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_piano_piece(file_path, hand=\"right\", use_white_black=False, aug=False):\n",
    "    \"\"\"\n",
    "    Loads data from a file, performs feature engineering\n",
    "    and optionally applies data augmentation using interval transpositions.\n",
    "\n",
    "    Returns:\n",
    "        list of PianoPiece objects\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    df.columns = [\"ID\", \"Onset\", \"Offset\", \"PitchName\", \"Column4\", \"Column5\", \"Beam\", \"Finger\"]\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"No data for {filepath}\")\n",
    "        return []\n",
    "    df = df.drop(columns=[\"Column4\", \"Column5\"])\n",
    "    \n",
    "    df[\"Onset\"] = df[\"Onset\"].astype(float)\n",
    "    df[\"Offset\"] = df[\"Offset\"].astype(float)\n",
    "    \n",
    "    # Select hand\n",
    "    df = df[df[\"Beam\"] == (0 if hand == \"right\" else 1)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"Finger\"] = df[\"Finger\"].astype(str).str.split('_').str[0].astype(int)\n",
    "    df = reorganize_fingers(df, hand=hand)\n",
    "    check_finger_ranges(df, hand, file_path)\n",
    "    \n",
    "    # numeric pitch and accidental flag\n",
    "    df[\"Note\"] = df[\"PitchName\"].apply(lambda x: pitch.Pitch(x).ps)\n",
    "    df[\"Accidental\"] = df[\"PitchName\"].apply(lambda x: int(pitch.Pitch(x).accidental is None))\n",
    "\n",
    "    # prepare diff columns\n",
    "    df[\"white_diff\"] = 0\n",
    "    df[\"black_diff\"] = 0\n",
    "    \n",
    "    if use_white_black:\n",
    "        for i in range(1, len(df)):\n",
    "            w, b = get_white_black_diff(df.loc[i-1,\"PitchName\"], df.loc[i,\"PitchName\"])\n",
    "            df.loc[i, \"white_diff\"] = w\n",
    "            df.loc[i, \"black_diff\"] = b\n",
    "\n",
    "    chord_labels = [\n",
    "        \"is_3_chord\", \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\",\n",
    "        \"is_4_chord\", \"is_5_chord\",\n",
    "    ]\n",
    "    for lbl in chord_labels:\n",
    "        df[lbl] = 0\n",
    "    df = mark_chords_with_type(df)\n",
    "\n",
    "    df[\"Duration\"] = (df[\"Offset\"] - df[\"Onset\"]).round(2)\n",
    "    \n",
    "    notes = df[\"Note\"].tolist()\n",
    "    fingers = df[\"Finger\"].tolist()\n",
    "    white_diff = df[\"white_diff\"].tolist()\n",
    "    black_diff = df[\"black_diff\"].tolist()\n",
    "    accidentals = df[\"Accidental\"].tolist()\n",
    "    ids = df[\"ID\"].astype(int).tolist()\n",
    "    onset = df[\"Onset\"].round(2).tolist()\n",
    "    offset = df[\"Offset\"].round(2).tolist()\n",
    "    \n",
    "    is_3_chord = df[\"is_3_chord\"].tolist()\n",
    "    is_4_chord = df[\"is_4_chord\"].tolist()\n",
    "    is_5_chord = df[\"is_5_chord\"].tolist()\n",
    "    chord_tonic = df[\"chord_tonic\"].tolist()\n",
    "    chord_sixth = df[\"chord_sixth\"].tolist()\n",
    "    chord_second_inversion = df[\"chord_second_inversion\"].tolist()\n",
    "    \n",
    "    intervals = np.diff(np.array(notes, dtype=int)).tolist()\n",
    "\n",
    "    # normalize fingers for loss calculation\n",
    "    if hand == \"right\":\n",
    "        fingers = [f - 1 for f in fingers]\n",
    "    else:\n",
    "        fingers = [-f - 1 for f in fingers]\n",
    "\n",
    "    piece = PianoPiece(\n",
    "        notes=notes,\n",
    "        fingers=fingers,\n",
    "        intervals=intervals,\n",
    "        accidentals=accidentals,\n",
    "        ids=ids,\n",
    "        # durations=durations,\n",
    "        onset=onset,\n",
    "        offset=offset,\n",
    "        white_diff=white_diff,\n",
    "        black_diff=black_diff,\n",
    "        \n",
    "        is_3_chord=is_3_chord,\n",
    "        is_4_chord=is_4_chord,\n",
    "        is_5_chord=is_5_chord,\n",
    "        chord_tonic=chord_tonic,\n",
    "        chord_sixth=chord_sixth,\n",
    "        chord_second_inversion=chord_second_inversion,\n",
    "        file_name=file_path\n",
    "    )\n",
    "\n",
    "    if aug:\n",
    "        pieces = []\n",
    "        for interval in interval_to_midi.values():\n",
    "            pieces.extend(interval_symmetry(piece, interval))\n",
    "        return pieces\n",
    "    else:\n",
    "        return [piece]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.900464Z",
     "iopub.status.busy": "2025-06-15T17:39:42.900045Z",
     "iopub.status.idle": "2025-06-15T17:39:42.911113Z",
     "shell.execute_reply": "2025-06-15T17:39:42.910186Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.900442Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def slide_window_future_gen(input_list, window_size, future_size):\n",
    "    \"\"\"\n",
    "    Generates sliding windows of fixed size from the input list, with the future part of the window set to zero.\n",
    "    \n",
    "    Args:\n",
    "        input_list (list): A list of input data (e.g., finger positions, intervals).\n",
    "        window_size (int): The length of the sliding window.\n",
    "        future_size (int): The number of future time steps to mask (set to zero).\n",
    "        \n",
    "    Yields:\n",
    "        list: A sliding window of size `window_size`, with the last `future_size` elements set to zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    for start in range(len(input_list) - window_size + 1):\n",
    "        full_list = input_list[start : start + window_size]\n",
    "        \n",
    "        for i in range(window_size-future_size, window_size):\n",
    "            full_list[i][0] = 0\n",
    "        \n",
    "        yield full_list\n",
    "\n",
    "\n",
    "def prepare_inputs(file_paths, hand=\"right\",  input_features=None, aug=False):\n",
    "    \"\"\"\n",
    "    Prepare inputs for the neural network.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - inputs (list): A list of input sequences for the neural network.\n",
    "            - labels (list): A list of target labels (finger positions) corresponding to the input sequences.\n",
    "            - processed_data (dict): A dictionary mapping each filename to the number of pieces processed.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    processed_data = {}\n",
    "    vector_list = []\n",
    "\n",
    "    if input_features is None:\n",
    "        input_features = [\"fingers\", \"intervals\", \"accidentals_current\", \"accidentals_next\"]\n",
    "        \n",
    "    # for filename in tqdm(sorted(filenames), desc=\"Processing Files\"):\n",
    "    for filename in sorted(file_paths):\n",
    "        vector_list = []\n",
    "        \n",
    "        if \"white_diff\" in input_features or \"black_diff\" in input_features:\n",
    "            pieces = load_piano_piece(filename, hand, use_white_black=True, aug=aug)\n",
    "        else:\n",
    "            pieces = load_piano_piece(filename, hand, aug=aug)\n",
    "            \n",
    "        for piece in pieces:\n",
    "            feature_matrix = piece.get_features(input_features)\n",
    "            vector_list.append(feature_matrix)\n",
    "            \n",
    "        processed_data[filename] = len(pieces)\n",
    "        \n",
    "        for i in range(len(vector_list)):\n",
    "            inputs.extend(\n",
    "                [l for l in slide_window_future_gen(vector_list[i], BLOCK_LENGTH, FUTURE_LENGTH)]\n",
    "            )\n",
    "            labels.extend(\n",
    "                [f for f in pieces[i].fingers[BLOCK_LENGTH - FUTURE_LENGTH : -FUTURE_LENGTH]]\n",
    "            )\n",
    "\n",
    "        \n",
    "    return inputs, labels, processed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.912242Z",
     "iopub.status.busy": "2025-06-15T17:39:42.911953Z",
     "iopub.status.idle": "2025-06-15T17:39:42.918518Z",
     "shell.execute_reply": "2025-06-15T17:39:42.917771Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.912220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PianoFingeringDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class for loading piano fingering data, designed for use with PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_paths, hand=\"right\", input_features=None, aug=False):\n",
    "        self.input_list, self.label_list, self.processed_data = prepare_inputs(file_paths, hand, input_features, aug)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = torch.tensor(self.input_list[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.label_list[idx], dtype=torch.int64)  \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.919742Z",
     "iopub.status.busy": "2025-06-15T17:39:42.919407Z",
     "iopub.status.idle": "2025-06-15T17:39:42.924705Z",
     "shell.execute_reply": "2025-06-15T17:39:42.923864Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.919714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_files(files, train_ratio, val_ratio, test_ratio):\n",
    "    train_files, temp_files = train_test_split(files, \n",
    "                                               test_size=(val_ratio + test_ratio), \n",
    "                                               random_state=48)\n",
    "    val_files, test_files = train_test_split(temp_files, \n",
    "                                             test_size=(test_ratio / (val_ratio + test_ratio)), \n",
    "                                             random_state=48)\n",
    "\n",
    "    return train_files, val_files, test_files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.925881Z",
     "iopub.status.busy": "2025-06-15T17:39:42.925569Z",
     "iopub.status.idle": "2025-06-15T17:39:42.932887Z",
     "shell.execute_reply": "2025-06-15T17:39:42.932025Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.925856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data_dir, batch_size, train_ratio, val_ratio, test_ratio, hand=\"right\", input_features=None, aug=False):\n",
    "    \"\"\"\n",
    "    Prepares the data by splitting it into train, validation, and test sets, then creates DataLoader objects.\n",
    "    \"\"\"\n",
    "\n",
    "    all_files = os.listdir(data_dir)\n",
    "\n",
    "    full_paths = [os.path.join(data_dir, f) for f in all_files]\n",
    "    \n",
    "    print(f\"Working with {hand} hand!\")\n",
    "    train_files, val_files, test_files = split_files(full_paths, train_ratio, val_ratio, test_ratio)\n",
    "\n",
    "    # print(f\"Train set {len(train_files)}\")\n",
    "    # print(f\"Vaidation set {len(val_files)}\")\n",
    "    # print(f\"Test set {len(test_files)}\\n\")\n",
    "    \n",
    "    train_dataset = PianoFingeringDataset(train_files, hand, input_features, aug)\n",
    "    val_dataset = PianoFingeringDataset(val_files, hand, input_features, aug)\n",
    "    test_dataset = PianoFingeringDataset(test_files, hand, input_features)\n",
    "\n",
    "    if aug:\n",
    "        len_train = 0\n",
    "        for i in train_dataset.processed_data.values():\n",
    "            len_train += int(i)\n",
    "        print(f\"Train set after aug {len_train}\")\n",
    "        \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_files, val_files, test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.934454Z",
     "iopub.status.busy": "2025-06-15T17:39:42.933849Z",
     "iopub.status.idle": "2025-06-15T17:39:42.940990Z",
     "shell.execute_reply": "2025-06-15T17:39:42.940120Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.934422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, block_length, future_length, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.block_length = block_length\n",
    "        self.future_length = future_length\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True, num_layers=num_layers)\n",
    "        self.lambda_layer_idx = block_length - future_length - 1\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "        selected_output = lstm_out[:, self.lambda_layer_idx, :]  \n",
    "        logits = self.fc(selected_output)  \n",
    "        probabilities = self.softmax(logits)\n",
    "        return probabilities\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"LSTM(h={self.hidden_size}, layers={self.num_layers}, block={self.block_length}, future={self.future_length})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.943879Z",
     "iopub.status.busy": "2025-06-15T17:39:42.943612Z",
     "iopub.status.idle": "2025-06-15T17:39:42.954244Z",
     "shell.execute_reply": "2025-06-15T17:39:42.953333Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.943858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 block_length,\n",
    "                 future_length,\n",
    "                 num_layers=1,\n",
    "                 n_heads=4,\n",
    "                 attn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.block_length = block_length\n",
    "        self.future_length = future_length\n",
    "        self.num_layers = num_layers\n",
    "        self.bi_dir_c = 2\n",
    "        self.lambda_layer_idx = block_length - future_length - 1\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size,\n",
    "                            hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.kdim = hidden_size * self.bi_dir_c\n",
    "        self.vdim = hidden_size * self.bi_dir_c\n",
    "        \n",
    "        self.q = nn.Linear(self.bi_dir_c * hidden_size, self.kdim)\n",
    "        self.k = nn.Linear(self.bi_dir_c * hidden_size, self.kdim)\n",
    "        self.v = nn.Linear(self.bi_dir_c * hidden_size, self.vdim)\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.bi_dir_c * hidden_size,\n",
    "            num_heads=n_heads,\n",
    "            dropout=attn_dropout,\n",
    "            kdim=self.kdim,\n",
    "            vdim=self.vdim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(self.bi_dir_c * hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "        self.fc = nn.Linear(self.bi_dir_c * hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        Q = self.q(lstm_out)\n",
    "        K = self.k(lstm_out)\n",
    "        V = self.v(lstm_out)\n",
    "        \n",
    "        attn_out, attn_weights = self.multihead_attn(Q, K, V)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        res = self.norm(lstm_out + attn_out)\n",
    "        selected = res[:, self.lambda_layer_idx, :]\n",
    "        \n",
    "        logits = self.fc(selected)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"LSTMWithAttention(h={self.hidden_size}, layers={self.num_layers}, \"\n",
    "                f\"block={self.block_length}, future={self.future_length}, heads={self.multihead_attn.num_heads})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.955334Z",
     "iopub.status.busy": "2025-06-15T17:39:42.955060Z",
     "iopub.status.idle": "2025-06-15T17:39:42.962288Z",
     "shell.execute_reply": "2025-06-15T17:39:42.961348Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.955314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, block_length, future_length, num_layers=1):\n",
    "        super(GRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.block_length = block_length\n",
    "        self.future_length = future_length\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, bidirectional=True, batch_first=True, num_layers=num_layers)\n",
    "        self.lambda_layer_idx = block_length - future_length - 1\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)  \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)  \n",
    "        selected_output = gru_out[:, self.lambda_layer_idx, :]  \n",
    "        logits = self.fc(selected_output)  \n",
    "        probabilities = self.softmax(logits)\n",
    "        return probabilities\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"GRU(h={self.hidden_size}, layers={self.num_layers}, block={self.block_length}, future={self.future_length})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.963414Z",
     "iopub.status.busy": "2025-06-15T17:39:42.963102Z",
     "iopub.status.idle": "2025-06-15T17:39:42.974520Z",
     "shell.execute_reply": "2025-06-15T17:39:42.973614Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.963390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GRUWithAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 output_size,\n",
    "                 block_length,\n",
    "                 future_length,\n",
    "                 num_layers=1,\n",
    "                 n_heads=4,\n",
    "                 attn_dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.block_length = block_length\n",
    "        self.future_length = future_length\n",
    "        self.num_layers = num_layers\n",
    "        self.bi_dir_c = 2\n",
    "        self.lambda_layer_idx = block_length - future_length - 1\n",
    "\n",
    "        self.gru = nn.GRU(input_size,\n",
    "                          hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        \n",
    "        self.kdim = hidden_size * self.bi_dir_c\n",
    "        self.vdim = hidden_size * self.bi_dir_c\n",
    "        \n",
    "        self.q = nn.Linear(self.bi_dir_c * hidden_size, self.kdim)\n",
    "        self.k = nn.Linear(self.bi_dir_c * hidden_size, self.kdim)\n",
    "        self.v = nn.Linear(self.bi_dir_c * hidden_size, self.vdim)\n",
    "        \n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.bi_dir_c * hidden_size,\n",
    "            num_heads=n_heads,\n",
    "            dropout=attn_dropout,\n",
    "            kdim=self.kdim,\n",
    "            vdim=self.vdim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(self.bi_dir_c * hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "        self.fc = nn.Linear(self.bi_dir_c * hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        Q = self.q(gru_out)\n",
    "        K = self.k(gru_out)\n",
    "        V = self.v(gru_out)\n",
    "        \n",
    "        attn_out, attn_weights = self.multihead_attn(Q, K, V)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        res = self.norm(gru_out + attn_out)\n",
    "        selected = res[:, self.lambda_layer_idx, :]\n",
    "        \n",
    "        logits = self.fc(selected)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"GRUWithAttention(h={self.hidden_size}, layers={self.num_layers}, \"\n",
    "                f\"block={self.block_length}, future={self.future_length}, heads={self.multihead_attn.num_heads})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.976508Z",
     "iopub.status.busy": "2025-06-15T17:39:42.975563Z",
     "iopub.status.idle": "2025-06-15T17:39:42.989059Z",
     "shell.execute_reply": "2025-06-15T17:39:42.988123Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.976482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, val_loader, num_epochs,\n",
    "                lr=0.001, weights=None, name=None, log_file=None):\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights.to(device) if weights is not None else None)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # List to store logs for each epoch\n",
    "    log_data = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss /= total\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs, labels) in enumerate(val_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                  f\"Train Loss: {epoch_loss:.4f}, \"\n",
    "                  f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "                  f\"Time: {epoch_time:.2f} sec \")\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "        log_data.append({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Train Loss': round(epoch_loss, 3),\n",
    "            'Train Accuracy': round(train_accuracy, 3),\n",
    "            'Val Loss': round(val_loss, 3),\n",
    "            'Val Accuracy': round(val_accuracy, 3)\n",
    "        })\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "    if name and best_model_state:\n",
    "        print(f\"Saving best model with validation accuracy {best_val_accuracy:.4f}\")\n",
    "        torch.save({\n",
    "            'model_state_dict': best_model_state,\n",
    "            'model_config': {\n",
    "                'input_size': model.input_size,\n",
    "                'hidden_size': model.hidden_size,\n",
    "                'output_size': model.fc.out_features,\n",
    "                'block_length': model.block_length,\n",
    "                'future_length': model.future_length,\n",
    "                'num_layers': model.num_layers\n",
    "            }\n",
    "        }, name)\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_df.to_csv(log_file, index=False)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.990238Z",
     "iopub.status.busy": "2025-06-15T17:39:42.989949Z",
     "iopub.status.idle": "2025-06-15T17:39:42.995046Z",
     "shell.execute_reply": "2025-06-15T17:39:42.994324Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.990203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_state_with_prediction(old_state, finger_pred, new_vec, future_size):\n",
    "    pred = old_state[-future_size]\n",
    "    pred[0] = finger_pred  # Update the predicted finger\n",
    "\n",
    "    # Updating the state with the new vector as a tensor\n",
    "    new_state = torch.tensor([0] + new_vec, dtype=torch.float32)\n",
    "    old_state[-future_size] = pred\n",
    "    return old_state[1:] + [new_state]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:42.997149Z",
     "iopub.status.busy": "2025-06-15T17:39:42.996058Z",
     "iopub.status.idle": "2025-06-15T17:39:43.002495Z",
     "shell.execute_reply": "2025-06-15T17:39:43.001593Z",
     "shell.execute_reply.started": "2025-06-15T17:39:42.997117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_test_inputs(file_path, hand=\"right\", input_features=None):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    if \"white_diff\" in input_features or \"black_diff\" in input_features:\n",
    "        pieces = load_piano_piece(file_path, hand, use_white_black=True)\n",
    "    else:\n",
    "        pieces = load_piano_piece(file_path, hand)\n",
    "        \n",
    "    feature_matrix = pieces[0].get_features(input_features)\n",
    "        \n",
    "    inputs.append(feature_matrix)\n",
    "    labels.append(pieces[0].fingers)\n",
    "    \n",
    "    return inputs, labels, pieces[0].ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:43.003702Z",
     "iopub.status.busy": "2025-06-15T17:39:43.003370Z",
     "iopub.status.idle": "2025-06-15T17:39:43.012716Z",
     "shell.execute_reply": "2025-06-15T17:39:43.011760Z",
     "shell.execute_reply.started": "2025-06-15T17:39:43.003673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_fingerings(input_list, label_list, model):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_vector, test_finger in zip(input_list, label_list):\n",
    "            init_state_b = [\n",
    "                torch.tensor([test_finger[i]] + test_vector[i], dtype=torch.float32)\n",
    "                for i in range(model.block_length - model.future_length)\n",
    "            ]\n",
    "            init_state_a = [\n",
    "                torch.tensor([0] + test_vector[i], dtype=torch.float32)\n",
    "                for i in range(model.block_length - model.future_length, model.block_length)\n",
    "            ]\n",
    "\n",
    "            init_state = init_state_b + init_state_a\n",
    "            num_intervals = len(test_vector)\n",
    "            temp_finger_res = []\n",
    "\n",
    "            for test_step in range(0, num_intervals - model.block_length + 1):\n",
    "                np_init_state = (\n",
    "                    torch.stack(init_state)\n",
    "                    .view(-1, model.block_length, model.input_size)\n",
    "                    .to(device)\n",
    "                )\n",
    "                \n",
    "                pred_prob = model(np_init_state)\n",
    "                finger_pred = torch.argmax(pred_prob, dim=1).item()\n",
    "                temp_finger_res.append(finger_pred)\n",
    "\n",
    "                if test_step < num_intervals - model.block_length - 1:\n",
    "                    next_vector = test_vector[test_step + model.block_length]\n",
    "                    init_state = update_state_with_prediction(\n",
    "                        init_state, finger_pred, next_vector, model.future_length\n",
    "                    )\n",
    "\n",
    "            temp_finger_res = (test_finger[: model.block_length - model.future_length] + temp_finger_res + test_finger[-model.future_length:])\n",
    "            results.append(temp_finger_res)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:43.014112Z",
     "iopub.status.busy": "2025-06-15T17:39:43.013670Z",
     "iopub.status.idle": "2025-06-15T17:39:43.021092Z",
     "shell.execute_reply": "2025-06-15T17:39:43.020097Z",
     "shell.execute_reply.started": "2025-06-15T17:39:43.014080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_fingering(test_files, hand, model, input_features):\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for file in test_files:\n",
    "        test_input_list, test_label_list, test_id_list = prepare_test_inputs(file, hand, input_features)\n",
    "        predicted_fingerings = predict_fingerings(test_input_list, test_label_list, model)\n",
    "        \n",
    "        flat_pred = [pred for pred in predicted_fingerings[0]]\n",
    "        # transformation = {4: 0, 0: 4, 3: 1, 1: 3}\n",
    "\n",
    "        # flat_pred = [transformation.get(pred, pred) for pred in flat_pred]\n",
    "\n",
    "        flat_label = [gt for gt in test_label_list[0]]\n",
    "        correct = sum(p == gt for p, gt in zip(flat_pred, flat_label))\n",
    "        total_correct += correct\n",
    "        total_predictions += len(flat_label)\n",
    "        \n",
    "        file_accuracy = correct / len(flat_label) if len(flat_label) > 0 else 0\n",
    "\n",
    "    overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    return overall_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:43.022409Z",
     "iopub.status.busy": "2025-06-15T17:39:43.022067Z",
     "iopub.status.idle": "2025-06-15T17:39:43.029817Z",
     "shell.execute_reply": "2025-06-15T17:39:43.028627Z",
     "shell.execute_reply.started": "2025-06-15T17:39:43.022376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_model(model_name, input_size, hidden_size, output_size, block_length, future_length, num_layers):\n",
    "    \"\"\"\n",
    "    Returns a model instance based on its name and parameters.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model, e.g., \"GRU\", \"LSTM\", etc.\n",
    "        input_size (int): Number of input features.\n",
    "        hidden_size (int): Size of the hidden layer.\n",
    "        output_size (int): Number of output classes.\n",
    "        block_length (int): Length of the input sequence.\n",
    "        future_length (int): Length of the future prediction sequence.\n",
    "        num_layers (int): Number of recurrent layers.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == \"GRU\":\n",
    "        return GRU(input_size, hidden_size, output_size, block_length, future_length, num_layers)\n",
    "    \n",
    "    elif model_name == \"LSTM\":\n",
    "        return LSTM(input_size, hidden_size, output_size, block_length, future_length, num_layers)\n",
    "    \n",
    "    elif model_name == \"LSTM_Attention\":\n",
    "        return LSTMWithAttention(input_size, hidden_size, output_size, block_length, future_length, num_layers)\n",
    "    \n",
    "    elif model_name == \"GRU_Attention\":\n",
    "        return GRUWithAttention(input_size, hidden_size, output_size, block_length, future_length, num_layers)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "\n",
    "def build_model_from_config(model_name, config):\n",
    "    \"\"\"\n",
    "    Builds a model by reading all required parameters from a config dictionary.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model architecture to use.\n",
    "        config (dict): Dictionary containing model parameters. Required keys:\n",
    "            - \"input_size\"\n",
    "            - \"hidden_size\"\n",
    "            - \"output_size\"\n",
    "            - \"block_length\"\n",
    "            - \"future_length\"\n",
    "            - \"num_layers\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return get_model(\n",
    "        model_name=model_name,\n",
    "        input_size=config[\"input_size\"],\n",
    "        hidden_size=config[\"hidden_size\"],\n",
    "        output_size=config[\"output_size\"],\n",
    "        block_length=config[\"block_length\"],\n",
    "        future_length=config[\"future_length\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:39:43.031158Z",
     "iopub.status.busy": "2025-06-15T17:39:43.030809Z",
     "iopub.status.idle": "2025-06-15T17:39:43.042224Z",
     "shell.execute_reply": "2025-06-15T17:39:43.041439Z",
     "shell.execute_reply.started": "2025-06-15T17:39:43.031127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_feature_experiments(model_name, features, n_hidden=32, num_layers=2, epochs=20):\n",
    "    EXPERIMENTS_ROOT = f\"{model_name.lower()}/experiments_inputs_{model_name.lower()}\"\n",
    "    os.makedirs(EXPERIMENTS_ROOT, exist_ok=True)\n",
    "\n",
    "    exp_counter = 1\n",
    "    results = []\n",
    "\n",
    "    for feature_set in features:\n",
    "        exp_dir = os.path.join(EXPERIMENTS_ROOT, f\"exp{exp_counter}\")\n",
    "        os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(exp_dir, \"features_name.txt\"), \"w\") as ff:\n",
    "            ff.write(\"\\n\".join(feature_set))\n",
    "\n",
    "        for hand in hands:\n",
    "            print(f\"\\nRunning experiment for {hand} hand with model {model_name}\")\n",
    "            print(f\"Features: {feature_set}\")\n",
    "\n",
    "            train_loader, val_loader, test_loader, _, val_files, test_files = prepare_data(\n",
    "                DATA_DIR, BATCH_SIZE, TRAIN_RATIO, VAL_RATIO, TEST_RATIO,\n",
    "                hand=hand, aug=False, input_features=feature_set\n",
    "            )\n",
    "            \n",
    "            model = get_model(\n",
    "                model_name=model_name,\n",
    "                input_size=len(feature_set),\n",
    "                hidden_size=n_hidden,\n",
    "                output_size=FINGER_SIZE,\n",
    "                block_length=BLOCK_LENGTH,\n",
    "                future_length=FUTURE_LENGTH,\n",
    "                num_layers=num_layers\n",
    "            )\n",
    "\n",
    "            model.to(device)\n",
    "\n",
    "            model_path = f\"{model_name.lower()}_b{BLOCK_LENGTH}_f{FUTURE_LENGTH}_hc{n_hidden}_nl{num_layers}_{hand}.pt\"\n",
    "            log_path = f\"log_b{BLOCK_LENGTH}_f{FUTURE_LENGTH}_hc{n_hidden}_nl{num_layers}_{hand}.csv\"\n",
    "\n",
    "            model = train_model(\n",
    "                model, device, train_loader, val_loader, num_epochs=epochs,\n",
    "                name=os.path.join(exp_dir, model_path),\n",
    "                log_file=os.path.join(exp_dir, log_path)\n",
    "            )\n",
    "\n",
    "            print(f\"\\nEvaluating {hand} hand\")\n",
    "            checkpoint = torch.load(os.path.join(exp_dir, model_path), weights_only=True)\n",
    "            config = checkpoint['model_config']\n",
    "\n",
    "            m = get_model(model_name, **config)\n",
    "            m.load_state_dict(checkpoint['model_state_dict'])\n",
    "            m.to(device)\n",
    "            \n",
    "            acc = evaluate_fingering(test_files, hand, m, feature_set[1:])\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Hand\": hand,\n",
    "                \"Hidden Size\": n_hidden,\n",
    "                \"Num Layers\": num_layers,\n",
    "                \"Block Length\": BLOCK_LENGTH,\n",
    "                \"Future Length\": FUTURE_LENGTH,\n",
    "                \"Inputs\": ', '.join(feature_set),\n",
    "                \"Accuracy\": round(acc, 3)\n",
    "            })\n",
    "\n",
    "        exp_counter += 1\n",
    "        print(\"__________________________________________________________\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(os.path.join(EXPERIMENTS_ROOT, f\"experiment_summary_inputs.csv\"), index=False)\n",
    "    print(f\"\\nSaved summary to {EXPERIMENTS_ROOT}/experiment_summary_inputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:41:02.578107Z",
     "iopub.status.busy": "2025-06-15T17:41:02.577811Z",
     "iopub.status.idle": "2025-06-15T17:44:04.542070Z",
     "shell.execute_reply": "2025-06-15T17:44:04.541157Z",
     "shell.execute_reply.started": "2025-06-15T17:41:02.578085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== LSTM ========================\n",
      "\n",
      "Running experiment for right hand with model LSTM\n",
      "Features: ['fingers', 'notes']\n",
      "Working with right hand!\n",
      "Epoch [1/1], Train Loss: 1.5811, Train Accuracy: 0.2694, Time: 13.01 sec \n",
      "Epoch [1/1], Val Loss: 1.4912, Validation Accuracy: 0.4010\n",
      "\n",
      "Saving best model with validation accuracy 0.4010\n",
      "\n",
      "Evaluating right hand\n",
      "Overall Accuracy: 0.4456\n",
      "\n",
      "\n",
      "Running experiment for left hand with model LSTM\n",
      "Features: ['fingers', 'notes']\n",
      "Working with left hand!\n",
      "Epoch [1/1], Train Loss: 1.3878, Train Accuracy: 0.5130, Time: 10.63 sec \n",
      "Epoch [1/1], Val Loss: 1.2831, Validation Accuracy: 0.6255\n",
      "\n",
      "Saving best model with validation accuracy 0.6255\n",
      "\n",
      "Evaluating left hand\n",
      "Overall Accuracy: 0.6462\n",
      "\n",
      "__________________________________________________________\n",
      "\n",
      "Running experiment for right hand with model LSTM\n",
      "Features: ['fingers', 'intervals']\n",
      "Working with right hand!\n",
      "Epoch [1/1], Train Loss: 1.3083, Train Accuracy: 0.5974, Time: 12.95 sec \n",
      "Epoch [1/1], Val Loss: 1.2731, Validation Accuracy: 0.6305\n",
      "\n",
      "Saving best model with validation accuracy 0.6305\n",
      "\n",
      "Evaluating right hand\n",
      "Overall Accuracy: 0.6693\n",
      "\n",
      "\n",
      "Running experiment for left hand with model LSTM\n",
      "Features: ['fingers', 'intervals']\n",
      "Working with left hand!\n",
      "Epoch [1/1], Train Loss: 1.2578, Train Accuracy: 0.6463, Time: 10.42 sec \n",
      "Epoch [1/1], Val Loss: 1.2089, Validation Accuracy: 0.6951\n",
      "\n",
      "Saving best model with validation accuracy 0.6951\n",
      "\n",
      "Evaluating left hand\n",
      "Overall Accuracy: 0.7181\n",
      "\n",
      "__________________________________________________________\n",
      "\n",
      "Running experiment for right hand with model LSTM\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next']\n",
      "Working with right hand!\n",
      "Epoch [1/1], Train Loss: 1.3074, Train Accuracy: 0.5965, Time: 12.76 sec \n",
      "Epoch [1/1], Val Loss: 1.2596, Validation Accuracy: 0.6522\n",
      "\n",
      "Saving best model with validation accuracy 0.6522\n",
      "\n",
      "Evaluating right hand\n",
      "Overall Accuracy: 0.6569\n",
      "\n",
      "\n",
      "Running experiment for left hand with model LSTM\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next']\n",
      "Working with left hand!\n",
      "Epoch [1/1], Train Loss: 1.2544, Train Accuracy: 0.6520, Time: 10.82 sec \n",
      "Epoch [1/1], Val Loss: 1.1985, Validation Accuracy: 0.7095\n",
      "\n",
      "Saving best model with validation accuracy 0.7095\n",
      "\n",
      "Evaluating left hand\n",
      "Overall Accuracy: 0.7313\n",
      "\n",
      "__________________________________________________________\n",
      "\n",
      "Saved summary to lstm/experiments_inputs_lstm/experiment_summary_inputs.csv\n"
     ]
    }
   ],
   "source": [
    "features_to_use = [\n",
    "                    [\"fingers\", \"notes\"],\n",
    "                    [\"fingers\", \"white_diff\", \"black_diff\"],\n",
    "                    [\"fingers\", \"intervals\"],\n",
    "                    [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\"],\n",
    "\n",
    "    \n",
    "                    [\"fingers\", \"intervals\", \"accidentals_current\", \"accidentals_next\"],\n",
    "                    [\"fingers\", \"notes\", \"accidentals_current\", \"accidentals_next\"],\n",
    "                    [\"fingers\", \"white_diff\", \"black_diff\", \"accidentals_current\", \"accidentals_next\"],\n",
    "                    [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\", \"accidentals_current\", \"accidentals_next\"],\n",
    "\n",
    "                    [\"fingers\", \"intervals\", \"is_3_chord\", \"is_4_chord\", \"is_5_chord\"],\n",
    "                    [\"fingers\", \"notes\", \"is_3_chord\", \"is_4_chord\", \"is_5_chord\"],\n",
    "                    [\"fingers\", \"white_diff\", \"black_diff\", \"is_3_chord\", \"is_4_chord\", \"is_5_chord\"],\n",
    "                    [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\", \"is_3_chord\", \"is_4_chord\", \"is_5_chord\"],\n",
    "    \n",
    "                    [\"fingers\", \"intervals\", \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                    [\"fingers\", \"notes\", \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                    [\"fingers\", \"white_diff\", \"black_diff\", \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                    [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\", \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                    \n",
    "                   \n",
    "                    [\"fingers\", \"intervals\", \"accidentals_current\", \"accidentals_next\", \n",
    "                     \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                    [\"fingers\", \"notes\", \"accidentals_current\", \"accidentals_next\", \n",
    "                     \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                     [\"fingers\",\"white_diff\", \"black_diff\", \"accidentals_current\", \"accidentals_next\", \n",
    "                     \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "                     [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\", \"accidentals_current\", \"accidentals_next\", \n",
    "                     \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "\n",
    "                    [\"fingers\", \"intervals\", \"white_diff\", \"black_diff\", \"accidentals_current\", \"accidentals_next\", \n",
    "                     \"is_3_chord\", \"is_4_chord\", \"is_5_chord\",\n",
    "                     \"chord_tonic\", \"chord_sixth\", \"chord_second_inversion\"],\n",
    "]\n",
    "\n",
    "\n",
    "print(\"======================== LSTM ========================\")\n",
    "run_feature_experiments(\"LSTM\", features_to_use, epochs=1)\n",
    "# print(\"======================== GRU ========================\")\n",
    "# run_feature_experiments(\"GRU\", features_to_use, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:44:29.876170Z",
     "iopub.status.busy": "2025-06-15T17:44:29.875347Z",
     "iopub.status.idle": "2025-06-15T17:44:29.906850Z",
     "shell.execute_reply": "2025-06-15T17:44:29.905840Z",
     "shell.execute_reply.started": "2025-06-15T17:44:29.876134Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Hand:\n",
      "                                            Features  Hand  Accuracy\n",
      "5  fingers, intervals, accidentals_current, accid...  left     0.731\n",
      "3                                 fingers, intervals  left     0.718\n",
      "1                                     fingers, notes  left     0.646\n",
      "\n",
      "Right Hand:\n",
      "                                            Features   Hand  Accuracy\n",
      "2                                 fingers, intervals  right     0.669\n",
      "4  fingers, intervals, accidentals_current, accid...  right     0.657\n",
      "0                                     fingers, notes  right     0.446\n",
      "\n",
      "Best Features Left: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next']\n",
      "Best Features Right: ['fingers', 'intervals']\n"
     ]
    }
   ],
   "source": [
    "def get_best_features(table):\n",
    "    return [feature.strip() for feature in table.loc[table['Accuracy'].idxmax(), 'Features'].split(',')]\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/working/lstm/experiments_inputs_lstm/experiment_summary_inputs.csv\")\n",
    "\n",
    "df['Inputs'] = df['Inputs'].str.replace('\"', '', regex=False)\n",
    "\n",
    "df.rename(columns={'Inputs': 'Features'}, inplace=True)\n",
    "\n",
    "df = df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "left_df = df[df['Hand'].str.lower() == 'left'][['Features', 'Hand', 'Accuracy']]\n",
    "right_df = df[df['Hand'].str.lower() == 'right'][['Features', 'Hand', 'Accuracy']]\n",
    "\n",
    "    \n",
    "print(\"Left Hand:\")\n",
    "print(left_df)\n",
    "\n",
    "print(\"\\nRight Hand:\")\n",
    "print(right_df)\n",
    "\n",
    "features_list_left = get_best_features(left_df)\n",
    "features_list_right = get_best_features(right_df)\n",
    "\n",
    "print(\"\\nBest Features Left:\", features_list_left)\n",
    "print(\"Best Features Right:\", features_list_right)\n",
    "\n",
    "left_df.to_csv(\"features_best_left.csv\")\n",
    "right_df.to_csv(\"features_best_right.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:45:07.028313Z",
     "iopub.status.busy": "2025-06-15T17:45:07.028003Z",
     "iopub.status.idle": "2025-06-15T17:45:07.039206Z",
     "shell.execute_reply": "2025-06-15T17:45:07.038291Z",
     "shell.execute_reply.started": "2025-06-15T17:45:07.028288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_hyperparam_experiments(\n",
    "    model_name,\n",
    "    features,\n",
    "    data_loaders,\n",
    "    hidden_sizes=[16, 32, 64],\n",
    "    num_layers_list=[1, 2, 3],\n",
    "    epochs=20,\n",
    "):\n",
    "    ROOT = f\"{model_name.lower()}/hyperparam_search\"\n",
    "    os.makedirs(ROOT, exist_ok=True)\n",
    "\n",
    "    records = []\n",
    "    exp_idx = 1\n",
    "\n",
    "    for hc in hidden_sizes:\n",
    "        for nl in num_layers_list:\n",
    "            exp_name = f\"exp{exp_idx}_hc{hc}_nl{nl}\"\n",
    "            exp_dir = os.path.join(ROOT, exp_name)\n",
    "            os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "            for hand in [\"right\", \"left\"]:\n",
    "                feature_set = features[hand]\n",
    "\n",
    "                with open(os.path.join(exp_dir, f\"features_{hand}.txt\"), \"w\") as f:\n",
    "                    f.write(\"\\n\".join(feature_set))\n",
    "\n",
    "                print(f\"\\nRunning experiment for {model_name.lower()} {hand} hand {exp_name}\")\n",
    "                print(\"Features:\", feature_set)\n",
    "\n",
    "                loaders = data_loaders[hand]\n",
    "\n",
    "                model = get_model(\n",
    "                    model_name=model_name,\n",
    "                    input_size=len(feature_set),\n",
    "                    hidden_size=hc,\n",
    "                    output_size=FINGER_SIZE,\n",
    "                    block_length=BLOCK_LENGTH,\n",
    "                    future_length=FUTURE_LENGTH,\n",
    "                    num_layers=nl\n",
    "                )\n",
    "                model.to(device)\n",
    "\n",
    "                model_path = f\"{model_name.lower()}_b{BLOCK_LENGTH}_f{FUTURE_LENGTH}_hc{hc}_nl{nl}_{hand}.pt\"\n",
    "                log_path = f\"log_b{BLOCK_LENGTH}_f{FUTURE_LENGTH}_hc{hc}_nl{nl}_{hand}.csv\"\n",
    "                \n",
    "                model = train_model(\n",
    "                    model, device,\n",
    "                    train_loader=loaders[\"train\"],\n",
    "                    val_loader=loaders[\"val\"],\n",
    "                    num_epochs=epochs,\n",
    "                    name=os.path.join(exp_dir, model_path),\n",
    "                    log_file=os.path.join(exp_dir, log_path)\n",
    "                )\n",
    "\n",
    "                print(f\"Evaluating {hand} hand\")\n",
    "                checkpoint = torch.load(os.path.join(exp_dir, model_path), map_location=device)\n",
    "                config = checkpoint[\"model_config\"]\n",
    "                m = get_model(model_name, **config)\n",
    "                m.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "                m.to(device)\n",
    "\n",
    "                acc = evaluate_fingering(loaders[\"test_files\"], hand, m, feature_set[1:])\n",
    "\n",
    "                records.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Hand\": hand,\n",
    "                    \"Hidden Size\": hc,\n",
    "                    \"Num Layers\": nl,\n",
    "                    \"Block Length\": BLOCK_LENGTH,\n",
    "                    \"Future Length\": FUTURE_LENGTH,\n",
    "                    \"Inputs\": ', '.join(feature_set),\n",
    "                    \"Accuracy\": round(acc, 3),\n",
    "                })\n",
    "\n",
    "            exp_idx += 1 \n",
    "            print(\"============================\")\n",
    "\n",
    "    summary = pd.DataFrame(records)\n",
    "    summary_path = os.path.join(ROOT, \"hyperparam_search_summary.csv\")\n",
    "    summary.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nSummary saved to {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:45:24.157018Z",
     "iopub.status.busy": "2025-06-15T17:45:24.156707Z",
     "iopub.status.idle": "2025-06-15T17:45:43.765195Z",
     "shell.execute_reply": "2025-06-15T17:45:43.763938Z",
     "shell.execute_reply.started": "2025-06-15T17:45:24.156995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with right hand!\n",
      "Working with left hand!\n"
     ]
    }
   ],
   "source": [
    "features_by_hand = {\n",
    "    # lstm best features\n",
    "    # \"right\":  ['fingers', 'intervals',  'chord_tonic', 'chord_sixth', 'chord_second_inversion'],\n",
    "    # \"left\":  ['fingers', 'intervals',  'chord_tonic', 'chord_sixth', 'chord_second_inversion'],\n",
    "\n",
    "    # gru best features\n",
    "    \"right\":  ['fingers', 'intervals', \"accidentals_current\", \"accidentals_next\", 'chord_tonic', 'chord_sixth', 'chord_second_inversion'],\n",
    "    \"left\":  ['fingers','intervals', \"accidentals_current\", \"accidentals_next\",  'chord_tonic', 'chord_sixth', 'chord_second_inversion'],\n",
    "}\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/pig-new\"\n",
    "# DATA_DIR = \"/kaggle/input/pig-own-data\"\n",
    "# DATA_DIR = \"/kaggle/input/own-piano-data\"\n",
    "\n",
    "data_loaders = {}\n",
    "for hand in [\"right\", \"left\"]:\n",
    "    features = features_by_hand[hand]\n",
    "\n",
    "    train_loader, val_loader, test_loader, \\\n",
    "    train_files, val_files, test_files = prepare_data(\n",
    "        DATA_DIR, BATCH_SIZE, TRAIN_RATIO, VAL_RATIO, TEST_RATIO,\n",
    "        hand=hand, aug=False, input_features=features\n",
    "    )\n",
    "\n",
    "    data_loaders[hand] = {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        \"test\": test_loader,\n",
    "        \"train_files\": train_files,\n",
    "        \"val_files\": val_files,\n",
    "        \"test_files\": test_files\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:45:49.602101Z",
     "iopub.status.busy": "2025-06-15T17:45:49.601802Z",
     "iopub.status.idle": "2025-06-15T17:47:34.077519Z",
     "shell.execute_reply": "2025-06-15T17:47:34.075907Z",
     "shell.execute_reply.started": "2025-06-15T17:45:49.602079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment for gru right hand exp1_hc16_nl1\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next', 'chord_tonic', 'chord_sixth', 'chord_second_inversion']\n",
      "Epoch [1/1], Train Loss: 1.3515, Train Accuracy: 0.5527, Time: 11.85 sec \n",
      "Epoch [1/1], Val Loss: 1.2963, Validation Accuracy: 0.6152\n",
      "\n",
      "Saving best model with validation accuracy 0.6152\n",
      "Evaluating right hand\n",
      "Overall Accuracy: 0.6409\n",
      "\n",
      "\n",
      "Running experiment for gru left hand exp1_hc16_nl1\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next', 'chord_tonic', 'chord_sixth', 'chord_second_inversion']\n",
      "Epoch [1/1], Train Loss: 1.2955, Train Accuracy: 0.6205, Time: 10.00 sec \n",
      "Epoch [1/1], Val Loss: 1.2265, Validation Accuracy: 0.6753\n",
      "\n",
      "Saving best model with validation accuracy 0.6753\n",
      "Evaluating left hand\n",
      "Overall Accuracy: 0.7039\n",
      "\n",
      "============================\n",
      "\n",
      "Running experiment for gru right hand exp2_hc16_nl2\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next', 'chord_tonic', 'chord_sixth', 'chord_second_inversion']\n",
      "Epoch [1/1], Train Loss: 1.3186, Train Accuracy: 0.5899, Time: 20.50 sec \n",
      "Epoch [1/1], Val Loss: 1.2701, Validation Accuracy: 0.6272\n",
      "\n",
      "Saving best model with validation accuracy 0.6272\n",
      "Evaluating right hand\n",
      "Overall Accuracy: 0.6484\n",
      "\n",
      "\n",
      "Running experiment for gru left hand exp2_hc16_nl2\n",
      "Features: ['fingers', 'intervals', 'accidentals_current', 'accidentals_next', 'chord_tonic', 'chord_sixth', 'chord_second_inversion']\n",
      "Epoch [1/1], Train Loss: 1.2705, Train Accuracy: 0.6362, Time: 17.25 sec \n",
      "Epoch [1/1], Val Loss: 1.2036, Validation Accuracy: 0.7026\n",
      "\n",
      "Saving best model with validation accuracy 0.7026\n",
      "Evaluating left hand\n",
      "Overall Accuracy: 0.7233\n",
      "\n",
      "============================\n",
      "\n",
      "Summary saved to gru/hyperparam_search/hyperparam_search_summary.csv\n"
     ]
    }
   ],
   "source": [
    "run_hyperparam_experiments(\n",
    "    model_name=\"GRU\",\n",
    "    features=features_by_hand,\n",
    "    data_loaders=data_loaders,\n",
    "    hidden_sizes=[16],\n",
    "    num_layers_list=[1, 2],\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-15T17:47:45.333218Z",
     "iopub.status.busy": "2025-06-15T17:47:45.332906Z",
     "iopub.status.idle": "2025-06-15T17:47:45.381860Z",
     "shell.execute_reply": "2025-06-15T17:47:45.380567Z",
     "shell.execute_reply.started": "2025-06-15T17:47:45.333193Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Num Layers</th>\n",
       "      <th>Hidden Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.621 / 0.675 / 0.704</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>left</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.636 / 0.703 / 0.723</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRU</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.553 / 0.615 / 0.641</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>right</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.590 / 0.627 / 0.648</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Hand  Num Layers  Hidden Size               Accuracy  \\\n",
       "0   GRU   left           1           16  0.621 / 0.675 / 0.704   \n",
       "2   GRU   left           2           16  0.636 / 0.703 / 0.723   \n",
       "1   GRU  right           1           16  0.553 / 0.615 / 0.641   \n",
       "3   GRU  right           2           16  0.590 / 0.627 / 0.648   \n",
       "\n",
       "   Train Accuracy  Val Accuracy  Test Accuracy  \n",
       "0           0.621         0.675          0.704  \n",
       "2           0.636         0.703          0.723  \n",
       "1           0.553         0.615          0.641  \n",
       "3           0.590         0.627          0.648  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the best combination of hyperparameters\n",
    "\n",
    "base_dir = \"/kaggle/working/gru/hyperparam_search\"\n",
    "\n",
    "summary_path = os.path.join(base_dir, \"hyperparam_search_summary.csv\")\n",
    "summary_df = pd.read_csv(summary_path)\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp_name in os.listdir(base_dir):\n",
    "    exp_path = os.path.join(base_dir, exp_name)\n",
    "    if os.path.isdir(exp_path) and exp_name.startswith(\"exp\"):\n",
    "        for hand in [\"left\", \"right\"]: \n",
    "            for file in os.listdir(exp_path):\n",
    "                if file.endswith(f\"_{hand}.csv\"):\n",
    "                    log_path = os.path.join(exp_path, file)\n",
    "                    log_df = pd.read_csv(log_path)\n",
    "\n",
    "                    best_val_idx = log_df[\"Val Accuracy\"].idxmax()\n",
    "                    train_acc = log_df.loc[best_val_idx, \"Train Accuracy\"]\n",
    "                    val_acc = log_df.loc[best_val_idx, \"Val Accuracy\"]\n",
    "\n",
    "                    exp_parts = file.split('_')\n",
    "                    \n",
    "                    block_len = int([s for s in exp_parts if s.startswith(\"b\")][0][1:])\n",
    "                    future_len = int([s for s in exp_parts if s.startswith(\"f\")][0][1:])\n",
    "                    hidden_size = int([s for s in exp_parts if s.startswith(\"hc\")][0][2:])\n",
    "                    num_layers = int([s for s in exp_parts if s.startswith(\"nl\")][0][2:])\n",
    "\n",
    "                    match = summary_df[\n",
    "                        (summary_df['Hand'] == hand)\n",
    "                        & (summary_df['Hidden Size'] == hidden_size)\n",
    "                        & (summary_df['Num Layers'] == num_layers)\n",
    "                        & (summary_df['Block Length'] == block_len)\n",
    "                        & (summary_df['Future Length'] == future_len)\n",
    "                    ]\n",
    "\n",
    "                    if not match.empty:\n",
    "                        test_acc = match['Accuracy'].values[0]\n",
    "                        model_name = match['Model'].values[0]\n",
    "                    else:\n",
    "                        print(f\"Не знайдено відповідності для {file}\")\n",
    "                        continue\n",
    "\n",
    "                    results.append({\n",
    "                        \"Model\": model_name,\n",
    "                        \"Hand\": hand,\n",
    "                        \"Hidden Size\": hidden_size,\n",
    "                        \"Num Layers\": num_layers,\n",
    "                        \"Train Accuracy\": train_acc,\n",
    "                        \"Val Accuracy\": val_acc,\n",
    "                        \"Test Accuracy\": test_acc\n",
    "                    })\n",
    "\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df[\"Accuracy\"] = final_df.apply(\n",
    "    lambda row: f\"{row['Train Accuracy']:.3f} / {row['Val Accuracy']:.3f} / {row['Test Accuracy']:.3f}\", axis=1\n",
    ")\n",
    "\n",
    "final_df = final_df[[\n",
    "    \"Model\", \"Hand\", \"Num Layers\", \"Hidden Size\",\n",
    "    \"Accuracy\", \"Train Accuracy\", \"Val Accuracy\", \"Test Accuracy\"\n",
    "]]\n",
    "\n",
    "hand_order = {\"left\": 0, \"right\": 1}\n",
    "final_df[\"HandOrder\"] = final_df[\"Hand\"].map(hand_order)\n",
    "final_df = final_df.sort_values(by=[\"HandOrder\", \"Num Layers\", \"Hidden Size\"]).drop(columns=\"HandOrder\")\n",
    "final_df\n",
    "\n",
    "# final_df.to_csv(\"/kaggle/working/hyperparam_results_sorted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-15T17:49:29.234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r exp_data_pig_own.zip /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_candidates = ['./data/pig/040-1_fingering.csv',\n",
    " './data/pig/026-5_fingering.csv',\n",
    " './data/pig/051-1_fingering.csv',\n",
    " './data/pig/030-4_fingering.csv',\n",
    " './data/pig/126-1_fingering.csv',\n",
    " './data/pig/022-3_fingering.csv',\n",
    " './data/pig/041-1_fingering.csv',\n",
    " './data/pig/003-5_fingering.csv',\n",
    " './data/pig/007-1_fingering.csv',\n",
    " './data/pig/047-2_fingering.csv',\n",
    " './data/pig/015-3_fingering.csv',\n",
    " './data/pig/097-1_fingering.csv',\n",
    " './data/pig/038-1_fingering.csv',\n",
    " './data/pig/019-3_fingering.csv',\n",
    " './data/pig/022-1_fingering.csv',\n",
    " './data/pig/141-1_fingering.csv',\n",
    " './data/pig/021-5_fingering.csv',\n",
    " './data/pig/020-3_fingering.csv',\n",
    " './data/pig/117-1_fingering.csv',\n",
    " './data/pig/012-3_fingering.csv',\n",
    " './data/pig/089-1_fingering.csv',\n",
    " './data/pig/064-1_fingering.csv',\n",
    " './data/pig/059-1_fingering.csv',\n",
    " './data/pig/053-1_fingering.csv',\n",
    " './data/pig/122-1_fingering.csv',\n",
    " './data/pig/011-1_fingering.csv',\n",
    " './data/pig/045-2_fingering.csv',\n",
    " './data/pig/046-1_fingering.csv',\n",
    " './data/pig/121-2_fingering.csv',\n",
    " './data/pig/087-1_fingering.csv',\n",
    " './data/pig/076-1_fingering.csv',\n",
    " './data/pig/131-1_fingering.csv',\n",
    " './data/pig/014-1_fingering.csv',\n",
    " './data/pig/011-3_fingering.csv',\n",
    " './data/pig/017-3_fingering.csv',\n",
    " './data/pig/028-4_fingering.csv',\n",
    " './data/pig/001-5_fingering.csv',\n",
    " './data/pig/113-1_fingering.csv',\n",
    " './data/pig/025-3_fingering.csv',\n",
    " './data/pig/032-3_fingering.csv',\n",
    " './data/pig/140-2_fingering.csv',\n",
    " './data/pig/004-8_fingering.csv',\n",
    " './data/pig/026-1_fingering.csv',\n",
    " './data/pig/011-5_fingering.csv',\n",
    " './data/pig/107-1_fingering.csv',\n",
    " './data/pig/001-8_fingering.csv',\n",
    " './data/pig/023-1_fingering.csv']"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6527006,
     "isSourceIdPinned": true,
     "sourceId": 10549015,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6655885,
     "sourceId": 10735025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7312501,
     "sourceId": 11652347,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7334099,
     "sourceId": 11685190,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6814830,
     "sourceId": 11780515,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7408863,
     "sourceId": 11798658,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6532140,
     "sourceId": 11933007,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7435694,
     "sourceId": 11944731,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7435708,
     "sourceId": 11944981,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7445428,
     "sourceId": 11945418,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
