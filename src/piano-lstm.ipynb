{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10549015,"sourceType":"datasetVersion","datasetId":6527006,"isSourceIdPinned":true},{"sourceId":10712301,"sourceType":"datasetVersion","datasetId":6532140},{"sourceId":10735025,"sourceType":"datasetVersion","datasetId":6655885},{"sourceId":10954726,"sourceType":"datasetVersion","datasetId":6814830}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from music21 import pitch\nfrom pprint import pprint, pformat\n\nimport os\nimport random\nimport csv\nimport math\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:12.629872Z","iopub.execute_input":"2025-03-07T15:19:12.630141Z","iopub.status.idle":"2025-03-07T15:19:17.945343Z","shell.execute_reply.started":"2025-03-07T15:19:12.630111Z","shell.execute_reply":"2025-03-07T15:19:17.944719Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"class PianoPiece:\n    def __init__(self, notes=[], fingers=[], intervals=[], accidentals=[], ids=[], duration=[], file_name=\"\"):\n        self.notes = notes\n        self.fingers = fingers\n        self.intervals = intervals\n        self.accidentals = accidentals\n        self.ids = ids\n        self.durations = duration\n        self.file_name = file_name\n\n\nclass PianoFingeringDataset(Dataset):\n    def __init__(self, filenames, data_dir, aug=False):\n        self.input_list, self.label_list, self.processed_data = prepare_inputs(filenames, data_dir, aug)\n\n    def __len__(self):\n        return len(self.input_list)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.input_list[idx], dtype=torch.float32)\n        y = torch.tensor(self.label_list[idx], dtype=torch.int64)  \n        return x, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:23.712751Z","iopub.execute_input":"2025-03-07T15:19:23.713038Z","iopub.status.idle":"2025-03-07T15:19:23.717581Z","shell.execute_reply.started":"2025-03-07T15:19:23.713015Z","shell.execute_reply":"2025-03-07T15:19:23.716674Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def reorganize_fingers(filename, data_dir):\n    \"\"\"\n    Reorganizes pitch data for chords in the right hand.\n\n    For each chord, the notes (and its rows) are sorted in ascending order.\n    Example: Given a chord G4, E4, and C4 is reordered as C4, E4, G4.\n    \"\"\"\n\n    data = []\n    pre_onset = 0\n    pre_row = None\n\n    filepath = data_dir + filename\n    df = pd.read_csv(filepath, header=None)\n    for index, row in df.iterrows():\n        min_index = 9999\n        data = []\n        current_onset = float(row[1])\n        current_finger = int(str(row.iloc[-1]).split('_')[0])  \n\n        if current_finger > 0: # right hand\n            if math.isclose(pre_onset, current_onset, rel_tol=1e-4):\n                for i in range(index - 1, index + 4, 1): # finding another notes of chord \n                    if i < len(df):\n                        if df.iloc[i, 1] == current_onset and str(df.iloc[i, -2]) == '0':\n                            if min_index > df.iloc[i, 0]:\n                                min_index = df.iloc[i, 0]\n                            data.append(df.iloc[i].tolist())\n                \n                data_sort = sorted(data.copy(), key = lambda x: float(pitch.Pitch(x[3]).ps))\n                for idx, value in enumerate(data_sort):\n                    value[0] = min_index + idx # changing the idx of note\n                \n                for i in range(min_index, len(data_sort) + min_index, 1):\n                    df.iloc[i] = data_sort[i - min_index]\n               \n        pre_onset = current_onset\n        pre_row = row.tolist()\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:21.943710Z","iopub.execute_input":"2025-03-07T15:19:21.943996Z","iopub.status.idle":"2025-03-07T15:19:21.950851Z","shell.execute_reply.started":"2025-03-07T15:19:21.943972Z","shell.execute_reply":"2025-03-07T15:19:21.950000Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"interval_to_midi = {\n    # \"Unison\": 0,\n    # \"Minor Second\": 1,\n    # \"Major Second\": 2,\n    # \"Minor Third\": 3,\n    # \"Major Third\": 4,\n    # \"Perfect Fourth\": 5,\n    # \"Tritone\": 6,\n    # \"Perfect Fifth\": 7,\n    # \"Minor Sixth\": 8,\n    # \"Major Sixth\": 9,\n    # \"Minor Seventh\": 10,\n    # \"Major Seventh\": 11,\n    \"Octave\": 12\n}\n\n\ndef pass_bounds(notes):\n    surpass = False\n    for n in notes:\n        if not (n == 0 or (21 <= n < 108)):\n            surpass = True\n    return surpass\n\n\ndef interval_symmetry(piece, interval):\n    \"\"\"\n    Generates symmetrical piece by applying interval shifts across multiple octaves.\n    \"\"\"\n    pieces = []\n    \n    octaves = [-9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n    for octave in octaves:\n        new_notes = [(n + (octave * interval)) if n != 0 else 0 for n in piece.notes]\n        if not pass_bounds(new_notes):\n            pieces.append(PianoPiece(new_notes, \n                                     piece.fingers, \n                                     piece.intervals, \n                                     piece.accidentals, \n                                     piece.ids, \n                                     piece.durations,\n                                     piece.file_name))\n    return pieces\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:34.569033Z","iopub.execute_input":"2025-03-07T15:19:34.569321Z","iopub.status.idle":"2025-03-07T15:19:34.575307Z","shell.execute_reply.started":"2025-03-07T15:19:34.569297Z","shell.execute_reply":"2025-03-07T15:19:34.574347Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def load_piano_piece(filename, data_dir, aug=False):\n    df = reorganize_fingers(filename, data_dir)\n    df.columns = [\"ID\", \"Onset\", \"Offset\", \"PitchName\", \"Column4\", \"Column5\", \"Channel\", \"Finger\"]\n    \n    df[\"Onset\"] = df[\"Onset\"].astype(float)\n    df[\"Offset\"] = df[\"Offset\"].astype(float)\n    df[\"Finger\"] = df[\"Finger\"].astype(str).str.split('_').str[0].astype(int)\n    df[\"Note\"] = df[\"PitchName\"].apply(lambda x: pitch.Pitch(x).ps)\n    df[\"Accidental\"] = df[\"PitchName\"].apply(lambda x: int(pitch.Pitch(x).accidental is None)) # whether note is black(0) or white(1) \n    \n    notes, fingers, accidentals, ids, durations = [], [], [], [], []\n    pre_onset = 0\n    \n    for _, row in df.iterrows():\n        if row[\"Finger\"] > 0:\n            notes.append(row[\"Note\"])\n            fingers.append(row[\"Finger\"])\n            accidentals.append(row[\"Accidental\"])\n            ids.append(int(row[\"ID\"]))\n            durations.append(round(row[\"Offset\"] - row[\"Onset\"], 2))\n        pre_onset = row[\"Onset\"]\n    \n    intervals = np.diff(np.array(notes, dtype=int)).tolist()\n    piece = PianoPiece(notes, fingers, intervals, accidentals, ids, durations, filename)\n    pieces = []\n    \n    if aug:\n        for interval in interval_to_midi.values():\n            res = interval_symmetry(piece, interval)\n            pieces.extend(res)\n        return pieces\n    else:\n        return [piece]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:41.546916Z","iopub.execute_input":"2025-03-07T15:19:41.547211Z","iopub.status.idle":"2025-03-07T15:19:41.555728Z","shell.execute_reply.started":"2025-03-07T15:19:41.547188Z","shell.execute_reply":"2025-03-07T15:19:41.554793Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def split_files(data_dir, train_ratio, val_ratio, test_ratio):\n    all_files = sorted(os.listdir(data_dir))\n    random.seed(42)\n    random.shuffle(all_files)  \n    total_files = len(all_files)\n\n    train_end = int(total_files * train_ratio)\n    val_end = train_end + int(total_files * val_ratio)\n\n    train_files = all_files[:train_end]\n    val_files = all_files[train_end:val_end]\n    test_files = all_files[val_end:]\n    \n    return train_files, val_files, test_files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:43.824328Z","iopub.execute_input":"2025-03-07T15:19:43.824668Z","iopub.status.idle":"2025-03-07T15:19:43.829313Z","shell.execute_reply.started":"2025-03-07T15:19:43.824639Z","shell.execute_reply":"2025-03-07T15:19:43.828395Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def prepare_inputs(filenames, data_dir, aug=False):\n\n    \"\"\"\n    Prepare inputs for the neural network.\n    \n    The input vector consists of:\n    1. Fingering of the current note\n    2. The semitone distance (midi) to the next note\n    3. Whether the current note is a black key\n    4. Whether the next note is a black key\n    5. Duration of the current note\n\n    The labels are fingers\n    \"\"\"\n\n    inputs = []\n    labels = []\n    processed_data = {}\n    \n    for filename in tqdm(sorted(filenames), desc=\"Processing Files\"):\n        vector_list = []\n        pieces = load_piano_piece(filename, data_dir, aug)\n        \n        for i in range(len(pieces)):\n            vector_list.append([\n                [f, il, bw_s, bw_e, dur]\n                for f, il, bw_s, bw_e, dur in zip(\n                    pieces[i].fingers[:-1],\n                    pieces[i].intervals,\n                    pieces[i].accidentals[:-1],\n                    pieces[i].accidentals[1:],\n                    pieces[i].durations[:-1]\n                )\n            ])\n        processed_data[filename] = len(pieces)\n        for i in range(len(vector_list)):\n            inputs.extend(\n                [l for l in slide_window_future_gen(vector_list[i], BLOCK_LENGTH, FUTURE_LENGTH)]\n            )\n            labels.extend(\n                [f for f in pieces[i].fingers[BLOCK_LENGTH - FUTURE_LENGTH : -FUTURE_LENGTH]]\n            )\n\n        \n    return inputs, labels, processed_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:20:54.335730Z","iopub.execute_input":"2025-03-07T16:20:54.336039Z","iopub.status.idle":"2025-03-07T16:20:54.342332Z","shell.execute_reply.started":"2025-03-07T16:20:54.336015Z","shell.execute_reply":"2025-03-07T16:20:54.341343Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"def create_dataloaders(data_dir, batch_size, train_ratio, val_ratio, test_ratio):\n    train_files, val_files, test_files = split_files(data_dir, train_ratio, val_ratio, test_ratio)\n\n    print(f\"Train set {len(train_files)}\")\n    print(f\"Vaidation set {len(val_files)}\")\n    print(val_files)\n    print(f\"Test set {len(test_files)}\")\n    print(test_files)\n    print()\n    \n    train_dataset = PianoFingeringDataset(train_files, data_dir, aug=True)\n    val_dataset = PianoFingeringDataset(val_files, data_dir)\n    test_dataset = PianoFingeringDataset(test_files, data_dir)\n\n    len_train = 0\n    \n    for i in train_dataset.processed_data.values():\n        len_train += int(i)\n    print(f\"Train set after {len_train}\")\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader, train_files, val_files, test_files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:59.167785Z","iopub.execute_input":"2025-03-07T15:19:59.168099Z","iopub.status.idle":"2025-03-07T15:19:59.175590Z","shell.execute_reply.started":"2025-03-07T15:19:59.168071Z","shell.execute_reply":"2025-03-07T15:19:59.174614Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, block_length, future_length):\n        super(LSTM, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True, num_layers=3)\n        self.lambda_layer_idx = block_length - future_length - 1\n        self.dropout = nn.Dropout(p=0.4)\n        self.fc = nn.Linear(hidden_size * 2, output_size)  \n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)  \n        selected_output = lstm_out[:, self.lambda_layer_idx, :]  \n        logits = self.fc(selected_output)  \n        probabilities = self.softmax(logits)\n        return probabilities\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:21:31.624080Z","iopub.execute_input":"2025-03-07T16:21:31.624391Z","iopub.status.idle":"2025-03-07T16:21:31.629869Z","shell.execute_reply.started":"2025-03-07T16:21:31.624368Z","shell.execute_reply":"2025-03-07T16:21:31.629065Z"}},"outputs":[],"execution_count":178},{"cell_type":"code","source":"def slide_window_future_gen(input_list, window_size, future_size):\n    for start in range(len(input_list) - window_size + 1):\n        full_list = input_list[start : start + window_size]\n        for i in range(window_size-future_size, window_size):\n            full_list[i][0] = 0\n        yield full_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T15:19:42.224789Z","iopub.execute_input":"2025-03-07T15:19:42.225104Z","iopub.status.idle":"2025-03-07T15:19:42.229407Z","shell.execute_reply.started":"2025-03-07T15:19:42.225075Z","shell.execute_reply":"2025-03-07T15:19:42.228394Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def train_model(model, device, train_loader, val_loader, num_epochs, name=None):\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(num_epochs):\n        start_time = time.time()  \n        \n        model.train()\n        epoch_loss = 0.0\n        correct = 0\n        total = 0\n\n        for idx, (inputs, labels) in enumerate(train_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels = labels - 1 \n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n        epoch_loss /= total\n        accuracy = correct / total\n        \n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for idx, (inputs, labels) in enumerate(val_loader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                labels = labels - 1 \n                \n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                val_correct += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n\n        val_loss /= val_total\n        val_accuracy = val_correct / val_total\n\n        epoch_time = time.time() - start_time\n\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n              f\"Loss: {epoch_loss:.4f}, \"\n              f\"Accuracy: {accuracy:.4f}, \"\n              f\"Time: {epoch_time:.2f} sec \")\n        \n        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n              f\"Val Loss: {val_loss:.4f}, \"\n              f\"Validation Accuracy: {val_accuracy:.4f}\")\n        print()\n\n    if name is not None:\n        print(f\"The model is saved as {name}\")\n        torch.save(model.state_dict(), name)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:21:33.641689Z","iopub.execute_input":"2025-03-07T16:21:33.641987Z","iopub.status.idle":"2025-03-07T16:21:33.650310Z","shell.execute_reply.started":"2025-03-07T16:21:33.641964Z","shell.execute_reply":"2025-03-07T16:21:33.649499Z"}},"outputs":[],"execution_count":179},{"cell_type":"code","source":"BLOCK_LENGTH = 11\nFUTURE_LENGTH = 5\nN_HIDDEN=128\nFINGER_SIZE = 5\nDATA_DIR = \"/kaggle/input/pig-dataset/\"\nBATCH_SIZE = 256\nNUM_EPOCHS = 20\nTRAIN_RATIO = 0.7\nVAL_RATIO = 0.25\nTEST_RATIO = 0.05\nINPUT_SIZE = 5\n\nblock_future = [(11, 5)]\n\n\ndef create_bi_direction_with_future_model(block_length, future_length):\n    return LSTM(input_size=INPUT_SIZE,  # Assuming input features are scalar\n                                       hidden_size=N_HIDDEN,\n                                       output_size=FINGER_SIZE,\n                                       block_length=block_length,\n                                       future_length=future_length)\n\n\n\n# block_future = [(7, 5), (8, 5), (9, 5), (10, 5), (11, 5),\n#                 (7, 4), (9, 4),\n#                 (11, 6), (11, 7), (11, 8),\n#                 (12, 8), (12, 9), (12, 4),\n#                 (15, 10), (15, 12),\n#                 (13, 8), (9, 6), (14, 10)\n#                ]\n    \ntrain_loader, val_loader, test_loader, train_files, val_files, test_files = create_dataloaders(DATA_DIR, BATCH_SIZE, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:21:51.652875Z","iopub.execute_input":"2025-03-07T16:21:51.653159Z","iopub.status.idle":"2025-03-07T16:22:39.249325Z","shell.execute_reply.started":"2025-03-07T16:21:51.653138Z","shell.execute_reply":"2025-03-07T16:22:39.248534Z"}},"outputs":[{"name":"stdout","text":"Train set 216\nVaidation set 77\n['072-1_fingering.csv', '014-1_fingering.csv', '004-5_fingering.csv', '066-1_fingering.csv', '065-1_fingering.csv', '076-1_fingering.csv', '018-3_fingering.csv', '049-2_fingering.csv', '013-6_fingering.csv', '128-2_fingering.csv', '124-1_fingering.csv', '043-1_fingering.csv', '015-7_fingering.csv', '112-1_fingering.csv', '024-5_fingering.csv', '106-1_fingering.csv', '014-6_fingering.csv', '059-1_fingering.csv', '028-3_fingering.csv', '011-5_fingering.csv', '109-1_fingering.csv', '035-1_fingering.csv', '005-5_fingering.csv', '044-1_fingering.csv', '129-1_fingering.csv', '097-1_fingering.csv', '052-1_fingering.csv', '015-6_fingering.csv', '047-2_fingering.csv', '013-3_fingering.csv', '019-4_fingering.csv', '020-1_fingering.csv', '011-3_fingering.csv', '019-7_fingering.csv', '074-2_fingering.csv', '042-1_fingering.csv', '115-2_fingering.csv', '145-1_fingering.csv', '020-5_fingering.csv', '012-7_fingering.csv', '138-1_fingering.csv', '121-1_fingering.csv', '030-5_fingering.csv', '024-3_fingering.csv', '006-8_fingering.csv', '009-8_fingering.csv', '020-6_fingering.csv', '058-1_fingering.csv', '031-1_fingering.csv', '011-1_fingering.csv', '063-2_fingering.csv', '014-7_fingering.csv', '093-1_fingering.csv', '006-5_fingering.csv', '028-1_fingering.csv', '050-1_fingering.csv', '056-1_fingering.csv', '012-5_fingering.csv', '064-1_fingering.csv', '140-1_fingering.csv', '144-1_fingering.csv', '048-1_fingering.csv', '023-1_fingering.csv', '017-5_fingering.csv', '131-1_fingering.csv', '049-1_fingering.csv', '142-1_fingering.csv', '017-7_fingering.csv', '001-8_fingering.csv', '029-4_fingering.csv', '087-1_fingering.csv', '023-4_fingering.csv', '075-1_fingering.csv', '143-1_fingering.csv', '021-3_fingering.csv', '132-1_fingering.csv', '004-2_fingering.csv']\nTest set 16\n['115-1_fingering.csv', '024-6_fingering.csv', '023-3_fingering.csv', '012-3_fingering.csv', '004-8_fingering.csv', '005-1_fingering.csv', '076-2_fingering.csv', '011-6_fingering.csv', '128-1_fingering.csv', '013-1_fingering.csv', '016-3_fingering.csv', '023-6_fingering.csv', '026-1_fingering.csv', '029-1_fingering.csv', '004-1_fingering.csv', '013-7_fingering.csv']\n\n","output_type":"stream"},{"name":"stderr","text":"Processing Files: 100%|██████████| 216/216 [00:34<00:00,  6.29it/s]\nProcessing Files: 100%|██████████| 77/77 [00:10<00:00,  7.00it/s]\nProcessing Files: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]","output_type":"stream"},{"name":"stdout","text":"<class 'dict'>\nTrain set after 1072\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":180},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nfor i in block_future:\n    BLOCK_LENGTH = i[0]\n    FUTURE_LENGTH = i[1]\n    model = create_bi_direction_with_future_model(BLOCK_LENGTH, FUTURE_LENGTH)\n    print(f\"Model is created with BLOCK_LENGTH = {BLOCK_LENGTH} and FUTURE_LENGTH = {FUTURE_LENGTH}\")\n    train_model(model, device, train_loader, val_loader, NUM_EPOCHS, f\"lstm_b{BLOCK_LENGTH}_f{FUTURE_LENGTH}.pt\")\n    print(\"__________________________________________________________\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:22:39.250312Z","iopub.execute_input":"2025-03-07T16:22:39.250577Z","iopub.status.idle":"2025-03-07T16:26:20.831821Z","shell.execute_reply.started":"2025-03-07T16:22:39.250555Z","shell.execute_reply":"2025-03-07T16:26:20.830682Z"}},"outputs":[{"name":"stdout","text":"cuda\nModel is created with BLOCK_LENGTH = 11 and FUTURE_LENGTH = 5\nEpoch [1/20], Loss: 1.2369, Accuracy: 0.6631, Time: 11.26 sec \nEpoch [1/20], Val Loss: 1.2176, Validation Accuracy: 0.6819\n\nEpoch [2/20], Loss: 1.1606, Accuracy: 0.7434, Time: 10.99 sec \nEpoch [2/20], Val Loss: 1.1823, Validation Accuracy: 0.7190\n\nEpoch [3/20], Loss: 1.1267, Accuracy: 0.7780, Time: 11.00 sec \nEpoch [3/20], Val Loss: 1.1802, Validation Accuracy: 0.7218\n\nEpoch [4/20], Loss: 1.1033, Accuracy: 0.8025, Time: 11.06 sec \nEpoch [4/20], Val Loss: 1.1732, Validation Accuracy: 0.7305\n\nEpoch [5/20], Loss: 1.0919, Accuracy: 0.8134, Time: 11.25 sec \nEpoch [5/20], Val Loss: 1.1788, Validation Accuracy: 0.7232\n\nEpoch [6/20], Loss: 1.0799, Accuracy: 0.8257, Time: 10.97 sec \nEpoch [6/20], Val Loss: 1.1662, Validation Accuracy: 0.7373\n\nEpoch [7/20], Loss: 1.0720, Accuracy: 0.8335, Time: 11.02 sec \nEpoch [7/20], Val Loss: 1.1722, Validation Accuracy: 0.7316\n\nEpoch [8/20], Loss: 1.0661, Accuracy: 0.8393, Time: 11.21 sec \nEpoch [8/20], Val Loss: 1.1759, Validation Accuracy: 0.7266\n\nEpoch [9/20], Loss: 1.0634, Accuracy: 0.8417, Time: 10.99 sec \nEpoch [9/20], Val Loss: 1.1768, Validation Accuracy: 0.7266\n\nEpoch [10/20], Loss: 1.0608, Accuracy: 0.8444, Time: 11.03 sec \nEpoch [10/20], Val Loss: 1.1752, Validation Accuracy: 0.7278\n\nEpoch [11/20], Loss: 1.0587, Accuracy: 0.8462, Time: 11.20 sec \nEpoch [11/20], Val Loss: 1.1767, Validation Accuracy: 0.7256\n\nEpoch [12/20], Loss: 1.0560, Accuracy: 0.8491, Time: 11.02 sec \nEpoch [12/20], Val Loss: 1.1754, Validation Accuracy: 0.7292\n\nEpoch [13/20], Loss: 1.0530, Accuracy: 0.8519, Time: 11.01 sec \nEpoch [13/20], Val Loss: 1.1750, Validation Accuracy: 0.7278\n\nEpoch [14/20], Loss: 1.0519, Accuracy: 0.8531, Time: 11.25 sec \nEpoch [14/20], Val Loss: 1.1783, Validation Accuracy: 0.7245\n\nEpoch [15/20], Loss: 1.0502, Accuracy: 0.8547, Time: 11.08 sec \nEpoch [15/20], Val Loss: 1.1771, Validation Accuracy: 0.7256\n\nEpoch [16/20], Loss: 1.0494, Accuracy: 0.8556, Time: 10.99 sec \nEpoch [16/20], Val Loss: 1.1785, Validation Accuracy: 0.7236\n\nEpoch [17/20], Loss: 1.0483, Accuracy: 0.8567, Time: 11.00 sec \nEpoch [17/20], Val Loss: 1.1758, Validation Accuracy: 0.7267\n\nEpoch [18/20], Loss: 1.0460, Accuracy: 0.8589, Time: 11.24 sec \nEpoch [18/20], Val Loss: 1.1739, Validation Accuracy: 0.7286\n\nEpoch [19/20], Loss: 1.0449, Accuracy: 0.8600, Time: 10.99 sec \nEpoch [19/20], Val Loss: 1.1746, Validation Accuracy: 0.7284\n\nEpoch [20/20], Loss: 1.0450, Accuracy: 0.8599, Time: 11.01 sec \nEpoch [20/20], Val Loss: 1.1774, Validation Accuracy: 0.7252\n\nThe model is saved as lstm_b11_f5.pt\n__________________________________________________________\n\n","output_type":"stream"}],"execution_count":181},{"cell_type":"markdown","source":"## Evaluating","metadata":{}},{"cell_type":"code","source":"def group_files_by_prefix(test_files):\n    file_dict = {}\n    for test_file in test_files:\n        pre_fix = test_file.split('-')[0]\n        if pre_fix in file_dict:\n            file_dict[pre_fix].append(test_file)\n        else:\n            temp_list = [test_file]\n            file_dict[pre_fix] = temp_list\n    return file_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:20.833367Z","iopub.execute_input":"2025-03-07T16:26:20.833663Z","iopub.status.idle":"2025-03-07T16:26:20.838153Z","shell.execute_reply.started":"2025-03-07T16:26:20.833641Z","shell.execute_reply":"2025-03-07T16:26:20.837513Z"}},"outputs":[],"execution_count":182},{"cell_type":"code","source":"def update_state_with_prediction(old_state, finger_pred, new_vec, future_size):\n    pred = old_state[-future_size]\n    pred[0] = finger_pred  # Update the predicted finger\n\n    # Updating the state with the new vector as a tensor\n    new_state = torch.tensor([0] + new_vec, dtype=torch.float32)\n    old_state[-future_size] = pred\n    return old_state[1:] + [new_state]  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:20.839056Z","iopub.execute_input":"2025-03-07T16:26:20.839250Z","iopub.status.idle":"2025-03-07T16:26:20.856996Z","shell.execute_reply.started":"2025-03-07T16:26:20.839232Z","shell.execute_reply":"2025-03-07T16:26:20.856220Z"}},"outputs":[],"execution_count":183},{"cell_type":"code","source":"def prepare_test_inputs(filename, data_dir):\n    inputs = []\n    labels = []\n\n    pieces = load_piano_piece(filename, data_dir)\n    vector = [\n        [il, bw_s, bw_e, dur]\n        for il, bw_s, bw_e, dur in zip(\n            pieces[0].intervals,\n            pieces[0].accidentals[:-1],\n            pieces[0].accidentals[1:],\n            pieces[0].durations[:-1]\n        )\n    ]\n        \n    inputs.append(vector)\n    labels.append(pieces[0].fingers)\n    \n    return inputs, labels, pieces[0].ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:20.857714Z","iopub.execute_input":"2025-03-07T16:26:20.857937Z","iopub.status.idle":"2025-03-07T16:26:20.871511Z","shell.execute_reply.started":"2025-03-07T16:26:20.857918Z","shell.execute_reply":"2025-03-07T16:26:20.870829Z"}},"outputs":[],"execution_count":184},{"cell_type":"code","source":"def predict_fingerings(input_list, label_list, model, device):\n    model.to(device)\n    model.eval()\n    results = []\n\n    with torch.no_grad():\n        for test_vector, test_finger in zip(input_list, label_list):\n            init_state_b = [\n                torch.tensor([test_finger[i]] + test_vector[i], dtype=torch.float32)\n                for i in range(BLOCK_LENGTH - FUTURE_LENGTH)\n            ]\n            init_state_a = [\n                torch.tensor([0] + test_vector[i], dtype=torch.float32)\n                for i in range(BLOCK_LENGTH - FUTURE_LENGTH, BLOCK_LENGTH)\n            ]\n\n            init_state = init_state_b + init_state_a\n            num_intervals = len(test_vector)\n            temp_finger_res = []\n\n            for test_step in range(0, num_intervals - BLOCK_LENGTH + 1):\n                np_init_state = (\n                    torch.stack(init_state)\n                    .view(-1, BLOCK_LENGTH, INPUT_SIZE)\n                    .to(device)\n                )\n                pred_prob = model(np_init_state)\n                finger_pred = torch.argmax(pred_prob, dim=1).item() + 1\n                temp_finger_res.append(finger_pred)\n\n                if test_step < num_intervals - BLOCK_LENGTH - 1:\n                    next_vector = test_vector[test_step + BLOCK_LENGTH]\n                    init_state = update_state_with_prediction(\n                        init_state, finger_pred, next_vector, FUTURE_LENGTH\n                    )\n\n            temp_finger_res = (test_finger[: BLOCK_LENGTH - FUTURE_LENGTH] + temp_finger_res + test_finger[-FUTURE_LENGTH:])\n            results.append(temp_finger_res)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:20.872225Z","iopub.execute_input":"2025-03-07T16:26:20.872421Z","iopub.status.idle":"2025-03-07T16:26:20.886825Z","shell.execute_reply.started":"2025-03-07T16:26:20.872403Z","shell.execute_reply":"2025-03-07T16:26:20.885997Z"}},"outputs":[],"execution_count":185},{"cell_type":"code","source":"def evaluate_fingering(test_files, model, device):\n    file_dict = group_files_by_prefix(test_files)\n    total_correct = 0\n    total_predictions = 0\n\n    for hmm_res_file in test_files:\n        pre_fix = hmm_res_file.split('-')[0]\n        \n        if pre_fix in file_dict:\n            test_input_list, test_label_list, test_id_list = prepare_test_inputs(hmm_res_file, DATA_DIR\\)\n            predicted_fingerings = predict_fingerings(test_input_list, test_label_list, model, device)\n            \n            flat_pred = [pred for pred in predicted_fingerings[0]]\n            flat_label = [gt for gt in test_label_list[0]]\n\n            correct = sum(p == gt for p, gt in zip(flat_pred, flat_label))\n            total_correct += correct\n            total_predictions += len(flat_label)\n            \n            file_accuracy = correct / len(flat_label) if len(flat_label) > 0 else 0\n            print(f\"File: {hmm_res_file} | Accuracy: {file_accuracy:.4f}\")\n\n    overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n    print(f\"Overall Categorical Accuracy: {overall_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:29.837000Z","iopub.execute_input":"2025-03-07T16:26:29.837293Z","iopub.status.idle":"2025-03-07T16:26:29.843044Z","shell.execute_reply.started":"2025-03-07T16:26:29.837269Z","shell.execute_reply":"2025-03-07T16:26:29.842258Z"}},"outputs":[],"execution_count":186},{"cell_type":"code","source":"model = create_bi_direction_with_future_model(BLOCK_LENGTH, FUTURE_LENGTH)\nmodel.load_state_dict(torch.load(\"/kaggle/working/lstm_b11_f5.pt\", weights_only=True))\n\n# for dirname, _, filenames in os.walk('/kaggle/working/new_csv_train'):\n#     for filename in filenames: \n#         test_files.append(filename)\n        \nevaluate_fingering(test_files,  model, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T16:26:37.430958Z","iopub.execute_input":"2025-03-07T16:26:37.431245Z","iopub.status.idle":"2025-03-07T16:26:42.130686Z","shell.execute_reply.started":"2025-03-07T16:26:37.431222Z","shell.execute_reply":"2025-03-07T16:26:42.129881Z"}},"outputs":[{"name":"stdout","text":"File: 115-1_fingering.csv | Accuracy: 0.7237\nFile: 024-6_fingering.csv | Accuracy: 0.7063\nFile: 023-3_fingering.csv | Accuracy: 0.7055\nFile: 012-3_fingering.csv | Accuracy: 0.6562\nFile: 004-8_fingering.csv | Accuracy: 0.7073\nFile: 005-1_fingering.csv | Accuracy: 0.6369\nFile: 076-2_fingering.csv | Accuracy: 0.7101\nFile: 011-6_fingering.csv | Accuracy: 0.7770\nFile: 128-1_fingering.csv | Accuracy: 0.8465\nFile: 013-1_fingering.csv | Accuracy: 0.6118\nFile: 016-3_fingering.csv | Accuracy: 0.6000\nFile: 023-6_fingering.csv | Accuracy: 0.7603\nFile: 026-1_fingering.csv | Accuracy: 0.8703\nFile: 029-1_fingering.csv | Accuracy: 0.7579\nFile: 004-1_fingering.csv | Accuracy: 0.5607\nFile: 013-7_fingering.csv | Accuracy: 0.6184\nOverall Categorical Accuracy: 0.7186\n","output_type":"stream"}],"execution_count":187}]}